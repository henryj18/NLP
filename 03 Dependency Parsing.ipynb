{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03 Dependency Parsing.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"88d5ace795d94cc7b3fb42f2373461ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_29b52f5939dc433a8f9af3ddddf45869","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_412a682cd93b4605be06c069f055cfa0","IPY_MODEL_229cb1ae6d4d4763a28c2dd029731a57","IPY_MODEL_32e89950b28040f18290716dc5256655"]}},"29b52f5939dc433a8f9af3ddddf45869":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"412a682cd93b4605be06c069f055cfa0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f4bda5c04d184492938c9f107c8c5a9f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_061233139ce340179110fd7f6fb3b75e"}},"229cb1ae6d4d4763a28c2dd029731a57":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_be0fb2bf001c4ee4b47f53b4da9c8d09","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":364,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":364,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_099f565746e348ff9332da29a75d27d4"}},"32e89950b28040f18290716dc5256655":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4eabee43b7924067ba1ea264955c414c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 364/364 [01:15&lt;00:00,  4.98it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fdd18daabd224da4b4eb38ed186e698f"}},"f4bda5c04d184492938c9f107c8c5a9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"061233139ce340179110fd7f6fb3b75e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be0fb2bf001c4ee4b47f53b4da9c8d09":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"099f565746e348ff9332da29a75d27d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4eabee43b7924067ba1ea264955c414c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fdd18daabd224da4b4eb38ed186e698f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"84562433f2d443d19c50d5f25252ba9b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7c8aef0343eb4784ad6eda4c540f4968","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7d2ca8b5b9dc47f7b7ddef7eafd30059","IPY_MODEL_f616727957804661878c05e7a68ac379","IPY_MODEL_34a2edb05f4c4e4c82db9a7e512af187"]}},"7c8aef0343eb4784ad6eda4c540f4968":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d2ca8b5b9dc47f7b7ddef7eafd30059":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ccd79962fa2e4304bcf5cfb6e73c98c3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb2c867fe7914b9a871abed5bccd163d"}},"f616727957804661878c05e7a68ac379":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_26d0331d277c43ecbf53aab0166cd0ce","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":364,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":364,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dca0e45d58574cf588b6578a6e7a6c55"}},"34a2edb05f4c4e4c82db9a7e512af187":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_042f51bfb05f4518a8c7c23df0192d81","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 364/364 [01:13&lt;00:00,  4.98it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_92b7abf7683e45e5a3e65df34a489b97"}},"ccd79962fa2e4304bcf5cfb6e73c98c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fb2c867fe7914b9a871abed5bccd163d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26d0331d277c43ecbf53aab0166cd0ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dca0e45d58574cf588b6578a6e7a6c55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"042f51bfb05f4518a8c7c23df0192d81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"92b7abf7683e45e5a3e65df34a489b97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b322f11bfaa1453e975cb014981dd119":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bb3b9744c28a4e58b36497bd2cb6cd48","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6bcfd693dec34c7ea47bfa7a66e232f2","IPY_MODEL_0611888de65f46fc9ff6e019aeb62189","IPY_MODEL_1c2d166f32984ca8b8d978f7b1a7af73"]}},"bb3b9744c28a4e58b36497bd2cb6cd48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6bcfd693dec34c7ea47bfa7a66e232f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9e1f9548dac44f45bdf705bf78d5a121","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_add00cf2857c407bbaaa9b26b7d7a8ab"}},"0611888de65f46fc9ff6e019aeb62189":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_120ce438072640f7beabb70117d2da7e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":364,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":364,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07c995fd9ffa4c1c885e81b5a36e2270"}},"1c2d166f32984ca8b8d978f7b1a7af73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_afca3e00fec0490eaf765981dcb1102a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 364/364 [01:13&lt;00:00,  4.97it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f37a0b4016cf4387bbd4691b7c4fcb3d"}},"9e1f9548dac44f45bdf705bf78d5a121":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"add00cf2857c407bbaaa9b26b7d7a8ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"120ce438072640f7beabb70117d2da7e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"07c995fd9ffa4c1c885e81b5a36e2270":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"afca3e00fec0490eaf765981dcb1102a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f37a0b4016cf4387bbd4691b7c4fcb3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e02823fea1094a84943eaa57bf4d0c81":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d1cbf59bcb7e4f25a109bbcac934bc87","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3b3cc769114c4d1e9e04c34f7629b083","IPY_MODEL_7299405560d3480ebfa471e5abba4fec","IPY_MODEL_e0db5931d4b84ff1acc51fc38eb7600d"]}},"d1cbf59bcb7e4f25a109bbcac934bc87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b3cc769114c4d1e9e04c34f7629b083":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_742de0621b084d44ba2d1a8dc3304ee1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_48ef8eaa8b3d4bfd8fdcaa6fd2df4b38"}},"7299405560d3480ebfa471e5abba4fec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a79a40d62c2c4f5aae764374465d2543","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":364,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":364,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2c60af015c6a423285efaf081a3fc00a"}},"e0db5931d4b84ff1acc51fc38eb7600d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_13525c61bae14170bdafc48036467c9d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 364/364 [01:13&lt;00:00,  4.92it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d59474974392427c88468fbffb22567e"}},"742de0621b084d44ba2d1a8dc3304ee1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"48ef8eaa8b3d4bfd8fdcaa6fd2df4b38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a79a40d62c2c4f5aae764374465d2543":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2c60af015c6a423285efaf081a3fc00a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13525c61bae14170bdafc48036467c9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d59474974392427c88468fbffb22567e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30eaf551b3da4dcf87695c35f0db0140":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c2bb0920d23344b2bc6e1c143c8b1366","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fc24ce9714604dc4acc79881b1d1c432","IPY_MODEL_d1d4712eb769434ebf06f127b126e73d","IPY_MODEL_bfd6bee118c542fba185877ce67a8a84"]}},"c2bb0920d23344b2bc6e1c143c8b1366":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc24ce9714604dc4acc79881b1d1c432":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_481f724cb16d4e219ae8a1ad996ce4de","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4f23b007f2234d409b4c173c7f258d66"}},"d1d4712eb769434ebf06f127b126e73d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_71a73ae3692d4299951afca809bbc7ea","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":364,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":364,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f73d40f392346f995d1aecefa9673bb"}},"bfd6bee118c542fba185877ce67a8a84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3dbfd657a1d64d849aaa83b225c26b90","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 364/364 [01:13&lt;00:00,  4.99it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ebd0426328dc412db87c5ba6c000283d"}},"481f724cb16d4e219ae8a1ad996ce4de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4f23b007f2234d409b4c173c7f258d66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71a73ae3692d4299951afca809bbc7ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7f73d40f392346f995d1aecefa9673bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3dbfd657a1d64d849aaa83b225c26b90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ebd0426328dc412db87c5ba6c000283d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e7dee40edbea4bbd8ce89b26bc05820b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_64c9405ed01d438a8502d193edbb9073","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_913a8aa0b0574272bedba07aec3c6b8d","IPY_MODEL_67cae0a1fe224e3e91215bd450e69a7a","IPY_MODEL_c147c0b7b689461db796c55bb7c421fd"]}},"64c9405ed01d438a8502d193edbb9073":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"913a8aa0b0574272bedba07aec3c6b8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_958d5ed3df1845b490f6a8a73cc9e9dd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d83e1b9223d145e3acb8af32c8181750"}},"67cae0a1fe224e3e91215bd450e69a7a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4b2dbeb319494991a4b27999b778166d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":364,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":364,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e919d4021ab421e9df16e2ebcf96e65"}},"c147c0b7b689461db796c55bb7c421fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2553fe61aeac40338b2592710a9769c5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 364/364 [01:13&lt;00:00,  4.93it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_deca7d770078448b8d0446de325ab15a"}},"958d5ed3df1845b490f6a8a73cc9e9dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d83e1b9223d145e3acb8af32c8181750":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4b2dbeb319494991a4b27999b778166d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6e919d4021ab421e9df16e2ebcf96e65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2553fe61aeac40338b2592710a9769c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"deca7d770078448b8d0446de325ab15a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b55a520e348346e495d6056770502c4a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6fc0e6bdb1a14bfe99eece3f4ce90750","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0e88ab9f35fe4c36bd83476227aca3f2","IPY_MODEL_02532ed5d1d6410a9f1ee9142cefeb0a","IPY_MODEL_fce07caf71c3425da99a0c7ce35446ea"]}},"6fc0e6bdb1a14bfe99eece3f4ce90750":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e88ab9f35fe4c36bd83476227aca3f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_143d051277fe452ab491946c3f584f4d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a70e3165d4f84c5899f1ae74b724d412"}},"02532ed5d1d6410a9f1ee9142cefeb0a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f8243cfea5a14a8aa47fd3a8992c2a69","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":364,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":364,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7edd6e8fd24a4cc486ff0b3ab3504d42"}},"fce07caf71c3425da99a0c7ce35446ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ab7139634aca4c068e8562804cf72e56","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 364/364 [01:13&lt;00:00,  5.03it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7dea3650262448fb9ae4676718020e9d"}},"143d051277fe452ab491946c3f584f4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a70e3165d4f84c5899f1ae74b724d412":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8243cfea5a14a8aa47fd3a8992c2a69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7edd6e8fd24a4cc486ff0b3ab3504d42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab7139634aca4c068e8562804cf72e56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7dea3650262448fb9ae4676718020e9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"629ef7eec4e842acaf19a25978a7186b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_37a6d91fac02411cbda2dc7937348b6e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_21e37ffc1d7b4e4e9854ecb05d0fb258","IPY_MODEL_da91e58fd9fb44aa8783dd0859e4d335","IPY_MODEL_6a3d4f589519474382b52fe728f4e91e"]}},"37a6d91fac02411cbda2dc7937348b6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21e37ffc1d7b4e4e9854ecb05d0fb258":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_221914e60cb74a03814bcc6b698d1d1c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f39378fcd65449209f3a6f3a59dc78e3"}},"da91e58fd9fb44aa8783dd0859e4d335":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4047d96b57954a84ac57096155039eae","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":364,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":364,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b5f1d695c3b4b7f88c53e26a810f550"}},"6a3d4f589519474382b52fe728f4e91e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a079c2fa3ce846afb81eb2c84afa8176","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 364/364 [01:13&lt;00:00,  4.98it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e3cceb8256341c4a162a421290075d3"}},"221914e60cb74a03814bcc6b698d1d1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f39378fcd65449209f3a6f3a59dc78e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4047d96b57954a84ac57096155039eae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3b5f1d695c3b4b7f88c53e26a810f550":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a079c2fa3ce846afb81eb2c84afa8176":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3e3cceb8256341c4a162a421290075d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58c0287546034a25b1ba50a15670b52b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_485545ddcc8a4b218f49abd0bbed612d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d71ca9dce7694c46b47ee7e81b63c24d","IPY_MODEL_b80d245b9426440bb93368f1bcb31535","IPY_MODEL_b02d6290fc364bd88c4149aaba2e5467"]}},"485545ddcc8a4b218f49abd0bbed612d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d71ca9dce7694c46b47ee7e81b63c24d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9bf77d245b9b453da9a3d28cbf422804","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4125961d04924a95acaf71e8f09589b8"}},"b80d245b9426440bb93368f1bcb31535":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7b4f3f2946d24ae7b46a666fa0509405","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":364,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":364,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_88b15e35f1a4447380abaa177e2a7b89"}},"b02d6290fc364bd88c4149aaba2e5467":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_939249fd4f684064bd221faa91ad0892","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 364/364 [01:13&lt;00:00,  4.93it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd698239122b449fa60dc77f1f005571"}},"9bf77d245b9b453da9a3d28cbf422804":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4125961d04924a95acaf71e8f09589b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b4f3f2946d24ae7b46a666fa0509405":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"88b15e35f1a4447380abaa177e2a7b89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"939249fd4f684064bd221faa91ad0892":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bd698239122b449fa60dc77f1f005571":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"36c7723bb1044413a97f885faa4d45c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1e391461254f4094b4bb72746fc245a8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_487200b12c7b4fd9b732c52e84273435","IPY_MODEL_724b7c6274c04af6947822cca66e33f9","IPY_MODEL_461aff7405ca430198d3255a95d6782a"]}},"1e391461254f4094b4bb72746fc245a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"487200b12c7b4fd9b732c52e84273435":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_95c63ffdf6464ca29723900bbadc8b81","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3643dac1994d463a8e031f772a760cc0"}},"724b7c6274c04af6947822cca66e33f9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7ad1338759ca405492b441fb203dcb56","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":364,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":364,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e8a67af146e454d85c3e9c2c19c7700"}},"461aff7405ca430198d3255a95d6782a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_010b617d71b0457ab9d4ec1fd352cd6d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 364/364 [01:13&lt;00:00,  4.96it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eacc31d6fca24c53a59275ebe11c5159"}},"95c63ffdf6464ca29723900bbadc8b81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3643dac1994d463a8e031f772a760cc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ad1338759ca405492b441fb203dcb56":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1e8a67af146e454d85c3e9c2c19c7700":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"010b617d71b0457ab9d4ec1fd352cd6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eacc31d6fca24c53a59275ebe11c5159":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"gau9xEXMGY8s"},"source":["# Dependency Parsing\n","Build a neural transition-based dependency parser, based on the paper <a href=\"https://nlp.stanford.edu/pubs/emnlp2014-depparser.pdf\">A Fast and Accurate Dependency Parser using Neural Networks</a>.\n","\n","We recommend runing this notebook on Google Colab instead of your local computer to avoid the hassle of installing necessary Python packages on local machine, and to get free GPU. Selecting \"GPU\" as the runtime type as this will speed up the training of your models. You can find this by going to <TT>Runtime > Change Runtime Type</TT> and select \"GPU\" from the dropdown menu.\n"]},{"cell_type":"markdown","metadata":{"id":"oetuJnpcKceg"},"source":["# Step 1: Prepare Data\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"mx_-2tlmkzju"},"source":["import numpy as np\n","import random\n","import cloudpickle as cp\n","from urllib.request import urlopen"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"16uFydR7ooyy"},"source":["## Load Data\n","\n","Here are some links about the data:\n","* We use one of the Universal Dependencies datasets from http://universaldependencies.org/docsv1/. Specifically, we use the UD_English dataset in version 1.4.\n","* Refer to https://universaldependencies.org/ if you want to know more about the Universal Dependencies framework in general.\n","* The data license can be found here: https://lindat.mff.cuni.cz/repository/xmlui/page/licence-UD-1.4\n","\n","Run the following cells to load the data and see the number of sentences."]},{"cell_type":"code","metadata":{"id":"llYdv429tNa3"},"source":["def load_data():\n","    # Note: these are the URLs from my own google drive, but tested it is assesible from any other google drive account  \n","    train_set = cp.load(urlopen(\"https://drive.google.com/uc?export=download&id=14RF97hFa42JqGn2K3Ew-RAr-YIgCQO6P\"))\n","    test_set = cp.load(urlopen(\"https://drive.google.com/uc?export=download&id=1WsYkm25JmqnFOJWk7KANPQ2TXNEBl8jE\"))\n","\n","    return train_set, test_set"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"USK3sLcNk8UM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646702492402,"user_tz":360,"elapsed":4847,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"91890a68-1b6e-4971-a3d1-8e0c3669110d"},"source":["if __name__ == '__main__':\n","    train_set, test_set = load_data()\n","    print(\"Num. Train Examples:\", len(train_set))\n","    print(\"Num. Test Examples: \", len(test_set))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num. Train Examples: 12543\n","Num. Test Examples:  2002\n"]}]},{"cell_type":"markdown","metadata":{"id":"u2w96HwRifLa"},"source":["## Build Vocabulary\n","\n","Next, we build the `Vocabulary` class. This maps each word, part-of-speech tag (POS), and label to an id (index), which we will later use in the embeddings. We also need to enumerate each possible transition, and map it to an id, since this is what the neural network will try to predict. The `Vocabulary` class does this as follows:\n","\n","Suppose there are $n$ labels. For each label, a Left-Arc (LA) and Right-Arc (RA) action are created for that label; and a separate Shift (S) action ids also created. This creates a total of $2n+1$ actions that the dependency parser will be able to choose from."]},{"cell_type":"code","metadata":{"id":"2e_6SR35jdyu"},"source":["class Vocabulary(object):\n","    def __init__(self, dataset):\n","\n","        UNK = '<UNK>'\n","        NULL = '<NULL>'\n","        ROOT = '<ROOT>'\n","\n","        # Find the label of the root\n","        root_labels = list([l for ex in dataset for (h, l) in zip(ex['head'], ex['label']) if h == 0])\n","        assert len(set(root_labels)) == 1\n","        self.root_label = root_labels[0]\n","\n","        # Create mapping from transitions to ids\n","        labels = sorted(list(set([w for ex in dataset for w in ex['label'] if w != self.root_label]))) # list of unique non-root labels\n","        labels = [self.root_label] + labels # add root label too\n","        self.n_labels = len(labels)\n","\n","        transitions = ['LA-' + l for l in labels] + ['RA-' + l for l in labels] + ['S']\n","        self.n_trans = len(transitions) # 2*n_labels + 1\n","        self.tran2id = {t: i for (i, t) in enumerate(transitions)}\n","        self.id2tran = {i: t for (i, t) in enumerate(transitions)}\n","\n","        # Create mapping from word, pos, & label to id\n","        # Do labels first\n","        self.LABEL_PREFIX = '<l>:'\n","        self.tok2id = {self.LABEL_PREFIX + l: i for (i, l) in enumerate(labels)}\n","        self.LABEL_NULL = self.tok2id[self.LABEL_PREFIX + NULL] = len(self.tok2id) # Add null label in\n","\n","        # Do POS's\n","        self.POS_PREFIX = '<p>:'\n","        all_pos = sorted(set([self.POS_PREFIX + w for ex in dataset for w in ex['pos']])) # Get pos's\n","        self.tok2id.update({w: index + len(self.tok2id) for (index, w) in enumerate(all_pos)}) # Add poses in\n","        self.POS_NULL = self.tok2id[self.POS_PREFIX + NULL] = len(self.tok2id) # Add null pos\n","        self.POS_ROOT = self.tok2id[self.POS_PREFIX + ROOT] = len(self.tok2id) # Add root pos\n","        self.n_pos = 2 + len(all_pos) # +3 for null, root\n","\n","        # Do words\n","        all_word = sorted(set([w for ex in dataset for w in ex['word']]))\n","        self.tok2id.update({w: index + len(self.tok2id) for (index, w) in enumerate(all_word)}) # Add words in\n","        self.WORD_UNK = self.tok2id[UNK] = len(self.tok2id) # Add unk word\n","        self.WORD_NULL = self.tok2id[NULL] = len(self.tok2id) # Add null word\n","        self.WORD_ROOT = self.tok2id[ROOT] = len(self.tok2id) # Add root word\n","        self.n_words = 3 + len(all_word) # +3 for unk, null, root\n","\n","        self.id2tok = {v: k for (k, v) in self.tok2id.items()} # Flip it\n","        self.n_tokens = len(self.tok2id)\n","\n","    def printStats(self):\n","        print('Num. labels:', self.n_labels)\n","        print('Num. transitions (2*n_labels + 1):', self.n_trans)\n","        print('Num. pos:', self.n_pos)\n","        print('Num. words:', self.n_words)\n","        print('Num. tokens:', self.n_tokens)\n","\n","\n","    def buildSentences(self, examples):\n","        processed_sentences = []\n","        for ex in examples:\n","            # Initialize words & dependencies\n","            words = [Word('<ROOT>', '<POS_ROOT>', 0, self.WORD_ROOT, self.POS_ROOT)]\n","            deps = [] \n","          \n","            # Loop over words in sentence\n","            for i  in  range(len(ex['word'])):\n","                w = ex['word'][i]\n","                word_id = (self.tok2id[w] if w in self.tok2id else self.WORD_UNK)\n","                pos = self.POS_PREFIX + ex['pos'][i]\n","                pos_id = self.tok2id[pos]\n","                word = Word(ex['word'][i], ex['pos'][i],i+1, word_id, pos_id)\n","\n","                words.append(word)\n","                deps.append((ex['head'][i], word, ex['label'][i] ))\n","            \n","            # Create dependencies\n","            dependencies = Dependencies(self)\n","            for dep in deps:\n","                dependencies.add(words[dep[0]], dep[1], dep[2])\n","\n","            processed_sentences.append((words, dependencies))\n","                      \n","        return processed_sentences"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0wzjGJj_mK_X"},"source":["Run the following cell to see some stats from the vocabulary."]},{"cell_type":"code","metadata":{"id":"O_ExUJ4ijnNu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646702514364,"user_tz":360,"elapsed":223,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"08841d53-a6d3-444f-9a20-f8b33f0c5768"},"source":["if __name__ == '__main__':\n","    Vocabulary(train_set).printStats()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num. labels: 47\n","Num. transitions (2*n_labels + 1): 95\n","Num. pos: 52\n","Num. words: 16635\n","Num. tokens: 16735\n"]}]},{"cell_type":"markdown","metadata":{"id":"iNJ1pSc5DnF4"},"source":["# Step 2: Parser Data Structures\n","In this section, some useful data structures for dependency parsing are defined. In particular, the `Stack` and `Buffer` structures are defined, which make up a `ParserConfiguration`. A function to update these data structures based on a particular transition is implemented also."]},{"cell_type":"markdown","metadata":{"id":"ZF5HszmJHNIu"},"source":["## Data Structures\n","\n","Some useful data classes are defined. "]},{"cell_type":"code","metadata":{"id":"3EnIONNfHP_U"},"source":["class Word(object):\n","    '''\n","    Represents a word in the sentence.\n","    '''\n","\n","    def __init__(self, word, pos, idx, word_id=None, pos_id=None):\n","        self.word = word\n","        self.pos = pos\n","        self.idx = idx\n","        self.word_id = word_id\n","        self.pos_id = pos_id\n","\n","    def __str__(self):\n","        return 'Word(idx=' + str(self.idx) + \", word='\" + self.word+\"', pos='\"+self.pos+\"', word_id=\"+str(self.word_id)+', pos_id='+ str(self.pos_id) +')'\n","\n","    def copy(self):\n","        return Word(self.word, self.pos, self.idx, self.word_id, self.pos_id)\n","\n","    def __eq__(self, obj):\n","        if not isinstance(obj, Word): return False\n","        if obj.idx == self.idx:\n","            assert obj.word == self.word and obj.pos == self.pos and obj.word_id == self.word_id and obj.pos_id == self.pos_id, 'Your Word object has been corrupted.'\n","        return obj.idx == self.idx\n","\n","\n","class Arc(object):\n","    '''\n","    Represents an arc between two words.\n","    '''\n","\n","    def __init__(self, head, dependent, label, label_id):\n","        self.head=head # Word object\n","        self.dependent=dependent # Word object\n","        self.label=label\n","        self.label_id = label_id\n","\n","    def __str__(self):\n","        return 'Arc(head_idx='+str(self.head.idx)+', dep_idx='+str(self.dependent.idx)+', label_id='+ str(self.label_id)+')'\n","\n","\n","class Dependencies(object):\n","    '''\n","    Represents the dependency arcs in a sentence.\n","    '''\n","\n","    def __init__(self, vocab):\n","        self.arcs = []\n","        self.vocab = vocab\n","        self.dep_to_head_mapping = {} # For fast lookup\n","    \n","    def add(self, head, dependent, label):\n","        '''\n","        Add a dependency from head to dependent with label.\n","        Inputs:\n","            head: Word object\n","            dependent: Word object\n","            label: str\n","        '''\n","        assert label[:3] != 'LA-' and label[:3] != 'RA-', 'You need to pass in just the label to add(...), not the entire action.'\n","        assert head is not None and dependent is not None, \"You must pass in two Word objects to add(...).\"\n","        self.arcs.append(Arc(head, dependent, label, self.vocab.tok2id[self.vocab.LABEL_PREFIX+label]))\n","        assert dependent.idx not in self.dep_to_head_mapping\n","        self.dep_to_head_mapping[dependent.idx] = self.arcs[-1]\n","\n","    def getArcToHead(self, dependent):\n","        '''\n","        Returns the Arc that connects the head of dependent to dependent.\n","        Inputs:\n","            dependent: Word object\n","        '''\n","        if dependent.idx == 0: # Special case for ROOT\n","            return Arc(None, dependent, None, None)\n","        return self.dep_to_head_mapping[dependent.idx]\n","\n","    def __iter__(self):\n","        return iter(self.arcs) # Allows to iterate \"for x in Dependencies(...)\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KZt_VfSQ4DLK"},"source":["## Stack & Buffer\n","\n","Define stack and buffer data structures, implement the `push(...)` and `pop(...)` methods of the `Stack`, and the `pop(...)` method of the `Buffer`. "]},{"cell_type":"code","metadata":{"id":"sWA0Hyz-N_LG"},"source":["class Stack(object):\n","    def __init__(self, input=[]):\n","        '''\n","        Initialize an (empty) stack.\n","        '''\n","        self.stack = [word.copy() for word in input] \n","\n","    def push(self, item):\n","        '''\n","        Push item onto (the end of) self.stack. Returns nothing.\n","        '''\n","\n","        self.stack.append(item)\n","\n","    def pop(self):        \n","        '''\n","        Pop item from (the end of) self.stack. Returns the item popped.\n","        '''\n","        assert len(self.stack) > 0\n","\n","        # remove the last item from the list self.stack, and return that item\n","        item = self.stack.pop(-1)\n","        return item\n","\n","    def get_si(self, i):\n","        '''\n","        Returns si (the ith element of the stack) if it exists, otherwise None.\n","        '''\n","        assert i > 0, 'Must provide i > 0'\n","        return self.stack[-i] if len(self.stack) >= i else None\n","\n","    def __getitem__(self, idx):\n","        return self.stack[idx]\n","\n","    def __len__(self):\n","        return len(self.stack)\n","\n","    def __str__(self):\n","        return str([str(x) for x in self.stack])\n","\n","\n","class Buffer(object):\n","    def __init__(self, sentence):\n","        '''\n","        Initialize as a list of words in sentence.\n","        '''\n","        self.buffer = [word.copy() for word in sentence]\n","\n","    def pop(self):\n","        '''\n","        Pop item from (the beginning of) self.buffer. Returns the item popped.\n","        '''\n","        assert len(self.buffer) > 0\n","        \n","        item = self.buffer.pop(0)\n","        return item\n","\n","    def get_bi(self, i):\n","        '''\n","        Returns bi (the ith element of the buffer) if it exists, otherwise None.\n","        '''\n","        assert i > 0, 'Must provide i > 0'\n","        return self.buffer[i-1] if len(self.buffer) >= i else None\n","\n","    def __getitem__(self, idx):\n","        return self.buffer[idx]\n","\n","    def __len__(self):\n","        return len(self.buffer)\n","\n","    def __str__(self):\n","        return str([str(x) for x in self.buffer])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9wZpV9p6K-_C"},"source":["## Parser Configuration\n","\n","Next, a `ParserConfiguration` class is created, which contains the `Stack`, `Buffer`, and `Dependencies` data structures. \n","\n","More specifically, let $\\sigma$ represent the stack, $\\beta$ the buffer, and $A$ the set of arcs (dependencies). Based on the value of `transition`, `parse_step(self, transition)` should do the following:\n","* `transition = 'S'`: &nbsp;<b>Shift</b> $w_k$ from the buffer to the stack. $(\\sigma, w_k|\\beta, A) \\Rightarrow (\\sigma|w_k, \\beta, A)$\n","* `transition = 'LA-label'`: &nbsp;Add a <b>left arc</b> with label $label$ from $w_j$ to $w_i$. $(\\sigma |w_i w_j , \\beta, A) \\Rightarrow (\\sigma |w_j, \\beta, A \\cup \\{(w_j, label, w_i)\\})$\n","* `transition = 'RA-label'`: &nbsp;Add a <b>right arc</b> with label $label$ from $w_i$ to $w_j$. $(\\sigma |w_i w_j , \\beta, A) \\Rightarrow (\\sigma |w_i, \\beta, A \\cup \\{(w_i, label, w_j)\\})$\n"]},{"cell_type":"code","metadata":{"id":"h3TbkOknPGzt"},"source":["class ParserConfiguration(object):\n","    def __init__(self, sentence, vocab):\n","        '''\n","        Inputs:\n","            sentence: list of Word objects\n","            vocab: Vocabulary object\n","        '''\n","\n","        self.vocab = vocab\n","\n","        assert sentence[0].word_id == self.vocab.WORD_ROOT\n","        # Initialize stack with ROOT\n","        self.stack = Stack([sentence[0]]) \n","        # Initialize buffer with sentence\n","        self.buffer = Buffer(sentence[1:]) \n","        self.dependencies = Dependencies(vocab)\n","\n","    def parse_step(self, transition):\n","        '''\n","        Update stack, buffer, and dependencies based on transition.\n","        Inputs:\n","            transition: str, \"S\", \"LA-label\", or \"RA-label\", where label is a valid label\n","        '''\n","        assert transition in self.vocab.tran2id\n","\n","\n","        if transition == \"S\": \n","            # shift\n","            word = self.buffer.pop()\n","            self.stack.push(word)\n","        elif transition.startswith(\"LA-\"):\n","            # Add a left arc - i.e arc from the top word to the 2nd word on stack, remove the 2nd word from stack\n","            # pop twice from the stack to remove the top two words, and then push back the top word\n","            # that is equivalent to removing the second word from the stack, then add the arc with the label           \n","            # transition[3:] is the label - starting index 3 to skip the first 3 chars \"LA-\" in transtion \n","            top_word = self.stack.pop()    # pop off the top word from stack\n","            second_word = self.stack.pop() # pop off the 2nd word\n","            self.stack.push(top_word)\n","            self.dependencies.add(top_word, second_word, transition[3:])\n","        elif transition.startswith(\"RA-\"):\n","            # Remove the top word from stack, add a right arc -  i.e. arc from the 2nd word to the top word on stack\n","            top_word = self.stack.pop()    # pop off the top word from stack\n","            # the second word of the original stack (before removing the top word) is now the top word - get_si(1)\n","            second_word = self.stack.get_si(1)\n","            self.dependencies.add(second_word, top_word, transition[3:]) \n","        else:\n","            # Something wrong with the transtion, print a warning message\n","            print(\"transtion error - \" + transition)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ty_IGY9KvFi"},"source":["# Step 3: Generate Training Data\n","\n","As shown above, the dataset contains many sentences along with their gold dependency parses. In order to use a transition-based parsing algorithm, the next parser action at each time step must be predicted, based on the current parser configuration. Thus, each sentence needs to be converted into a series of training examples, where the input features are based on the current parser configuration and the correct label is the gold action.\n","\n","In this section, we first implement an algorithm to select the next parser action at each time step based on the gold dependency parse. Then, we will extract features from each step's parser configuration, which the neural network will use to predict the next action."]},{"cell_type":"markdown","metadata":{"id":"sZSOg7bCdqFz"},"source":["## Compute Gold Action\n","\n","Next, we will write a function `get_gold_action(stack, buffer, gold_dependencies)`. Given a stack and buffer, this function should return the next action of the parser based on the gold dependencies. \n","\n","Let $s_i$ be $i$th element of the stack and $h(s_i)$ be the head word of $s_i$. The pseudocode is as follows:\n","\n","1. If the stack only contains `ROOT`:\n"," - If the buffer is not empty, return `S` (shift).\n"," - If the buffer is empty, return `DONE`, indicating the parse is complete.\n","2. If $h(s_2)=s_1$, return `LA-label`. Here, `label` is the label of the arc that attaches $s_2$ to $s_1$.\n","3. If $h(s_1)=s_2$ <b>and</b> $h(b_i) \\neq s_1$ for all words $b_i$ in the buffer, return `RA-label`. Here, `label` is the label of the arc that attaches $s_1$ to $s_2$.\n"," - This condition means that you cannot attach $s_1$ until everything in the buffer that depends on $s_1$ is attached. \n","4. Otherwise:\n"," - If the buffer is not empty, return `S`. \n"," - If the buffer is empty, return `None`, indicating a failed parse (i.e., the sentence is non-projective).\n"]},{"cell_type":"code","metadata":{"id":"NoZRaLj-z1Ss"},"source":["def get_gold_action(stack, buffer, gold_dependencies):\n","    '''\n","    Given stack & buffer, compute the next gold action based on gold_dependencies.\n","    Args:\n","        - stack: Stack object\n","        - buffer: Buffer object\n","        - gold_dependencies: Dependencies object\n","    Returns:\n","        - action: str; 'S', 'LA-label', or 'RA-label', where 'label' is a valid label. Return None if no action possible and 'DONE' if the parse is complete.\n","    '''\n","\n","\n","    # 1. if stack only cntains ROOT, i.e. len(stack) == 1\n","    if len(stack) == 1: #len() can be called because __len__ is defined in Stack class\n","        if len(buffer) > 0:     \n","            return 'S'\n","        else:\n","            return 'DONE'\n","    \n","    # 2. If h(s2) = s1 return LA-label\n","    s1 = stack.get_si(1)\n","    s2 = stack.get_si(2)\n","    arc = gold_dependencies.getArcToHead(s2)\n","    if arc.head == s1:\n","        action = \"LA-\" + arc.label\n","        return action\n","\n","    # 3. If h(s1) = s2 and h(bi) /= s1 for all ... return RA-label\n","    arc = gold_dependencies.getArcToHead(s1)\n","    if arc.head == s2:\n","        count = 0\n","        for bi in buffer:    # this for loop can be used because __getitem__ is defined in Buffer class\n","            if gold_dependencies.getArcToHead(bi).head == s1:\n","                count += 1\n","                break\n","        if count == 0: \n","        # There exist no bi such that h(bi) == s1, i.e. h(bi) /= s1 for all bi in buffer\n","            action = \"RA-\" + arc.label\n","            return action\n","    # 4. Otherwise:\n","    if len(buffer) > 0:\n","        return 'S'\n","    else:\n","        return None\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FgGQNEEAp8o3"},"source":["## Generate Training Examples\n","\n","\n","Now implement a function to generate the training examples. Each sentence needs to be converted into a series of separate training examples. Each training example will essentially be a partial parser configuration along with its gold action; the goal of the neural network will be to predict this action from the parser configuration.\n","\n","In order to make this prediction, we need to extract features from the parser configuration. We will implement the feature extraction method in a future section; for now, we pass in a dummy function `feat_extract(parser_config)` that returns an empty feature list.\n"]},{"cell_type":"code","metadata":{"id":"hfrlMo6tkm1M"},"source":["def generate_training_examples(sentence, gold_dependencies, vocab, feat_extract = lambda parser_config: []):\n","    '''\n","    Create training instances for sentence.\n","    Inputs:\n","        sentence: list of Word objects\n","        gold_dependencies: Dependencies object that contains the complete gold dependency tree\n","        vocab: Vocabulary object\n","        feat_extract: Feature extraction function\n","    Outputs:\n","        training_examples: List of tuples (features, label), where features is a list and label is a string\n","    '''\n","\n","    training_examples = []\n","\n","    # (1) Initialize parser configuration (note that the __init__ method of ParserConfiguration creates the stack & buffer)\n","    parser_config = ParserConfiguration(sentence, vocab)\n","    # (2) Repeatedly call get_gold_action(...) on the current parser confuration until the gold action is 'DONE'\n","    gold_action = get_gold_action(parser_config.stack, parser_config.buffer, gold_dependencies)\n","    while gold_action != 'DONE':\n","          # (3) If the gold action is None at any step, return []  \n","          # (indicating the sentence cannot be parsed; it is non-projective)\n","          if gold_action == None:\n","              training_examples = []\n","              break\n","          # (4) Otherwise, append tuple (features, gold action) to training_examples, \n","          # where features is the result of calling feat_extract on the parser configuration\n","          features = feat_extract(parser_config)\n","          training_examples.append((features, gold_action))\n","          #(5) Update the parser configuration according to the gold action\n","          parser_config.parse_step(gold_action) \n","          gold_action = get_gold_action(parser_config.stack, parser_config.buffer, gold_dependencies)\n","    # (6) Return training_examples\n","    return training_examples"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PRMxUrAZp0hM"},"source":["The following function calls `generate_training_examples(...)` on every sentence in the dataset to create the full training data."]},{"cell_type":"code","metadata":{"id":"tVbUIQN4X-rz"},"source":["def generate_all_training_examples(vocab, sentences, feat_extract = lambda parser_config: []):\n","    '''\n","    Generate training examples for all sentences.\n","    '''\n","    all_training_examples = []\n","    successful_sents = 0\n","    for sentence in sentences:\n","        training_examples = generate_training_examples(sentence[0], sentence[1], vocab, feat_extract)\n","        if training_examples != []:\n","            all_training_examples += training_examples\n","            successful_sents += 1\n","\n","    print(\"Successfully generated training examples for\", successful_sents, \"/\", len(sentences), \"sentences\")\n","    print(\"Number of training examples:\", len(all_training_examples))\n","\n","    return all_training_examples"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"LUBkdAfdDEW1"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwi0kw6Jfzxp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646702550147,"user_tz":360,"elapsed":6516,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"53e12327-5d01-4bc8-8c29-53e2b2b992b2"},"source":["if __name__ == '__main__':\n","    _vocab = Vocabulary(train_set)\n","    generate_all_training_examples(_vocab, _vocab.buildSentences(train_set))    \n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully generated training examples for 11888 / 12543 sentences\n","Number of training examples: 373100\n"]}]},{"cell_type":"markdown","metadata":{"id":"yDXMtwn6IJM3"},"source":["## Extract Features\n","By this point, we have written code to create individual training instances. Each instance is made up of a parser configuration along with the gold action that the classifier should be trained to predict.\n","\n","In order to make this prediction, the neural network will have to rely on features extracted from each parser configuration. We follow the procedure described at the end of Section 3.1 of <a href=\"https://nlp.stanford.edu/pubs/emnlp2014-depparser.pdf\">A Fast and Accurate Dependency Parser using Neural Networks</a>. In total, we will extract 48 features from the parser configuration $-$ 18 word features, 18 POS features, and 12 label features:\n","* Word & POS features for $s_1$, $s_2$, $s_3$ (top 3 items of the stack)\n","* Word & POS features for $b_1$, $b_2$, $b_3$ (top 3 items of the buffer)\n","* Word, POS, & label features for $lc_1(s_1)$, $lc_2(s_1)$, $lc_1(s_2)$, $lc_2(s_2)$ (the first & second leftmost children of the top 2 items on the stack)\n","* Word, POS, & label features for $rc_1(s_1)$, $rc_2(s_1)$, $rc_1(s_2)$, $rc_2(s_2)$ (the first & second rightmost children of the top 2 items on the stack)\n","* Word, POS, & label features for $lc_1(lc_1(s_1))$, $lc_1(lc_1(s_2))$, $rc_1(rc_1(s_1))$, $rc_1(rc_1(s_2))$ (the leftmost of the leftmost & rightmost of the rightmost children of the top 2 items on the stack)\n","\n","We will write a separate function for each of the 5 bullets above. Each function will return a list of word features, a list of POS features, and (in the relevant cases) a list of label features. \n","\n","A \"feature\" refers to the id (index in the Vocabulary) of a word, POS, or label. The neural network will then construct embeddings for each id."]},{"cell_type":"markdown","metadata":{"id":"psFHnbnMQ7rh"},"source":["First, write 2 functions to extract features corresponding to the words at the top of the stack & buffer:\n","* `get_top3_stack_features(parser_config)`: Return word & POS features (ids) for $s_1$, $s_2$, $s_3$ (top 3 words on the stack).\n","* `get_top3_buffer_features(parser_config)`: Return word & POS features (ids) for $b_1$, $b_2$, $b_3$ (top 3 words on the buffer).\n","\n","Wherever a particular word does not exist (such as when the stack or buffer has length $< 3$) use the appropriate NULL token. This is necessary to ensure that the neural network will see an equally sized feature vector for each example."]},{"cell_type":"code","metadata":{"id":"_Afl9vxuRtxN"},"source":["def get_top3_stack_features(parser_config):\n","    '''\n","    Get the word and POS features for s1, s2, and s3 (the top 3 items on the stack)\n","    Returns:\n","        word_features: List of word ids for s1, s2, s3 (use vocab.WORD_NULL if a word does not exist)\n","        pos_features: List of POS ids for s1, s2, s3 (use vocab.POS_NULL if a word does not exist)\n","    '''\n","\n","    stack = parser_config.stack\n","    vocab = parser_config.vocab\n","    if len(stack) >= 3:\n","        s1 = stack.get_si(1)\n","        s2 = stack.get_si(2)\n","        s3 = stack.get_si(3)\n","        word_features = [s1.word_id, s2.word_id, s3.word_id]\n","        pos_features  = [s1.pos_id, s2.pos_id, s3.pos_id]\n","\n","    elif len(stack) == 2:\n","        s1 = stack.get_si(1)\n","        s2 = stack.get_si(2)\n","        word_features = [s1.word_id, s2.word_id, vocab.WORD_NULL]\n","        pos_features  = [s1.pos_id, s2.pos_id, vocab.POS_NULL]\n","\n","    elif len(stack) == 1:\n","        s1 = stack.get_si(1)\n","        word_features = [s1.word_id, vocab.WORD_NULL, vocab.WORD_NULL]\n","        pos_features  = [s1.pos_id, vocab.POS_NULL, vocab.POS_NULL]\n","    else:   \n","        # i.e. len(stack) == 0, this should not happen, since stack should at least have ROOT\n","        # If it happens, print warning message\n","        print(\"Inside get_top3_stack_features, len(stack) == 0\")\n","\n","    return word_features, pos_features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u7KKlAcf8-dm"},"source":["def get_top3_buffer_features(parser_config):\n","    '''\n","    Get the word and POS features for b1, b2, and b3 (the top 3 items on the buffer)\n","    Returns:\n","        word_features: List of word ids for b1, b2, b3 (use vocab.WORD_NULL if a word does not exist)\n","        pos_features: List of POS ids for b1, b2, b3 (use vocab.POS_NULL if a word does not exist)\n","    '''\n","\n","    buffer = parser_config.buffer\n","    vocab = parser_config.vocab\n","    if len(buffer) >= 3:\n","        b1 = buffer.get_bi(1)\n","        b2 = buffer.get_bi(2)\n","        b3 = buffer.get_bi(3)\n","        word_features = [b1.word_id, b2.word_id, b3.word_id]\n","        pos_features  = [b1.pos_id, b2.pos_id, b3.pos_id]\n","\n","    elif len(buffer) == 2:\n","        b1 = buffer.get_bi(1)\n","        b2 = buffer.get_bi(2)\n","        word_features = [b1.word_id, b2.word_id, vocab.WORD_NULL]\n","        pos_features  = [b1.pos_id, b2.pos_id, vocab.POS_NULL]\n","\n","    elif len(buffer) == 1:\n","        b1 = buffer.get_bi(1)\n","        word_features = [b1.word_id, vocab.WORD_NULL, vocab.WORD_NULL]\n","        pos_features  = [b1.pos_id, vocab.POS_NULL, vocab.POS_NULL]\n","    else:   #len(buffer) == 0\n","        word_features = [vocab.WORD_NULL, vocab.WORD_NULL, vocab.WORD_NULL]\n","        pos_features  = [vocab.POS_NULL, vocab.POS_NULL, vocab.POS_NULL]\n","\n","    return word_features, pos_features\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"09zcpPdWUe2a"},"source":["The remaining features have to do with the leftmost & rightmost children of the words at the top of the stack & buffer. Write the following 2 helper functions to make it easier to access these dependents:\n","* `get_lc(parser_config, word)`: Return a list of arcs to dependents of `word`, sorted from <b>left to right</b>. Only include dependents that are to the <b>left</b> of `word` in the sentence.\n","* `get_rc(parser_config, word)`: Return a list of arcs to dependents of `word`, sorted from <b>right to left</b>. Only include dependents that are to the <b>right</b> of `word` in the sentence.\n"]},{"cell_type":"code","metadata":{"id":"MCu-UWopILGy"},"source":["def get_lc(parser_config, word):\n","    '''\n","    Finds the left dependents of word, sorted from left to right.\n","    Returns:\n","        A list of Arcs whose head is word, sorted by the indices of the dependent word from left to right.\n","    '''\n","\n","    arcs = []\n","    # use this \"for loop\" cooresponding to __iter__ defined in Dependencies class\n","    for arc in parser_config.dependencies: \n","        if arc.head == word and arc.dependent.idx < word.idx: # dependent is left to head in the sentence\n","            if len(arcs) == 0:\n","                arcs.append(arc)\n","            else:   # len(arcs) >= 1\n","                for i in range(len(arcs)):\n","                    if arc.dependent.idx < arcs[i].dependent.idx:\n","                        arcs.insert(i, arc)\n","                        inserted = True\n","                        break\n","                if inserted == False:\n","                    arcs.append(arc)\n","    return arcs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yu8bcii49Ais"},"source":["def get_rc(parser_config, word):\n","    '''\n","    Finds the right dependents of word, sorted from right to left.\n","    Returns:\n","        A list of Arcs whose head is word, sorted by the indices of the dependent word from right to left.\n","    '''\n","\n","    arcs = []\n","    # use this \"for loop\" cooresponding to __iter__ defined in Dependencies class\n","    for arc in parser_config.dependencies:  \n","        if arc.head == word and arc.dependent.idx > word.idx: # dependent is right to head in the sentence\n","            if len(arcs) == 0:\n","                arcs.append(arc)\n","            else:   # len(arcs) >= 1\n","                for i in range(len(arcs)):\n","                    if arc.dependent.idx > arcs[i].dependent.idx:\n","                        arcs.insert(i, arc)\n","                        inserted = True\n","                        break\n","                if inserted == False:\n","                    arcs.append(arc)\n","    return arcs    \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GgvnzwesXoxT"},"source":["Let $lc_j(s_i)$ be the $j$th leftmost child of the $i$th item on the stack. Write the following function:\n","* `get_lc1_lc2_features(parser_config, i)`: Return word & POS features for $lc_1(s_i)$ and $lc_2(s_i)$. Additionally, return label features (the label ids) for the arcs that attach $lc_1(s_i)$ to $s_i$ and $lc_2(s_i)$ to $s_i$. As before, wherever a particular word does not exist, use the appropriate NULL token.\n","\n","This function will be called with `i=1` and `i=2`, accounting for the words $lc_1(s_1)$, $lc_2(s_1)$, $lc_1(s_2)$, $lc_2(s_2)$."]},{"cell_type":"code","metadata":{"id":"oOUWfviTW4cf"},"source":["def get_lc1_lc2_features(parser_config, i):\n","    '''\n","    Get the word, POS, and label features for lc1(si) and lc2(si), where i in {1, 2}\n","    Returns:\n","        word_features: List of word ids for lc1(si), lc2(si) (use vocab.WORD_NULL if a word does not exist)\n","        pos_features: List of POS ids for lc1(si), lc2(si) (use vocab.POS_NULL if a word does not exist)\n","        label_features: List of label ids for lc1(si), lc2(si) (use vocab.LABEL_NULL if a word does not exist)\n","    '''\n","    assert i in {1,2}\n","\n","    word = parser_config.stack.get_si(i)\n","    arcs = get_lc(parser_config, word)\n","    if len(arcs) == 0:\n","        word_features, pos_features, label_features = [parser_config.vocab.WORD_NULL]*2, [parser_config.vocab.POS_NULL]*2, [parser_config.vocab.LABEL_NULL]*2\n","    elif len(arcs) == 1:\n","        word_features = [arcs[0].dependent.word_id, parser_config.vocab.WORD_NULL]\n","        pos_features = [arcs[0].dependent.pos_id, parser_config.vocab.POS_NULL]\n","        label_features = [arcs[0].label_id, parser_config.vocab.LABEL_NULL]\n","    else:  #len(arcs) >= 2\n","        word_features = [arcs[0].dependent.word_id, arcs[1].dependent.word_id]\n","        pos_features = [arcs[0].dependent.pos_id, arcs[1].dependent.pos_id]\n","        label_features = [arcs[0].label_id, arcs[1].label_id]\n","        \n","    return word_features, pos_features, label_features\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ujGRbd1Ma8w3"},"source":["We will now write the analagous function for the rightmost children. Let $rc_j(s_i)$ be the $j$th rightmost child of the $i$th item on the stack. Write the following function:\n","* `get_rc1_rc2_features(parser_config, i)`: Return word & POS features for $rc_1(s_i)$ and $rc_2(s_i)$. Additionally, return label features (the label ids) for the arcs that attach $rc_1(s_i)$ to $s_i$ and $rc_2(s_i)$ to $s_i$. As before, wherever a particular word does not exist, use the appropriate NULL token.\n","This function will be called with `i=1` and `i=2`, accounting for the words $rc_1(s_1)$, $rc_2(s_1)$, $rc_1(s_2)$, $rc_2(s_2)$."]},{"cell_type":"code","metadata":{"id":"4y6SKXd9a4SI"},"source":["def get_rc1_rc2_features(parser_config, i):\n","    '''\n","    Get the word, POS, and label features for rc1(si) and rc2(si), where i in {1, 2}\n","    Returns:\n","        word_features: List of word ids for rc1(si), rc2(si) (use vocab.WORD_NULL if a word does not exist)\n","        pos_features: List of POS ids for rc1(si), rc2(si) (use vocab.POS_NULL if a word does not exist)\n","        label_features: List of label ids for rc1(si), rc2(si) (use vocab.LABEL_NULL if a word does not exist)\n","    '''\n","    assert i in {1,2}\n","\n","    word = parser_config.stack.get_si(i)\n","    arcs = get_rc(parser_config, word)\n","    if len(arcs) == 0:\n","        word_features, pos_features, label_features = [parser_config.vocab.WORD_NULL]*2, [parser_config.vocab.POS_NULL]*2, [parser_config.vocab.LABEL_NULL]*2\n","    elif len(arcs) == 1:\n","        word_features = [arcs[0].dependent.word_id, parser_config.vocab.WORD_NULL]\n","        pos_features = [arcs[0].dependent.pos_id, parser_config.vocab.POS_NULL]\n","        label_features = [arcs[0].label_id, parser_config.vocab.LABEL_NULL]\n","    else:  #len(arcs) >= 2\n","        word_features = [arcs[0].dependent.word_id, arcs[1].dependent.word_id]\n","        pos_features = [arcs[0].dependent.pos_id, arcs[1].dependent.pos_id]\n","        label_features = [arcs[0].label_id, arcs[1].label_id]\n","\n","    return word_features, pos_features, label_features"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BKtZ3smFhXqK"},"source":["Finally, write the following function:\n","* `get_llc_rrc_features(parser_config, i)`: Return word & POS features for $lc_1(lc_1(s_i))$ and $rc_1(rc_1(s_i))$. Additionally, return label features (the label ids) for the arcs that attach $lc_1(lc_1(s_i))$ to $lc_1(s_i)$ and $rc_1(rc_1(s_i))$ to $rc_1(s_i)$. As before, wherever a particular word does not exist, use the appropriate NULL token.\n","\n","This function will be called with `i=1` and `i=2`, accounting for the words $lc_1(lc_1(s_1))$, $lc_1(lc_1(s_2))$, $rc_1(rc_1(s_1))$, $rc_1(rc_1(s_2))$."]},{"cell_type":"code","metadata":{"id":"tbmTbX96hTAH"},"source":["def get_llc_rrc_features(parser_config, i):\n","    '''\n","    Get the word, POS, and label features for lc1(lc1(si)), and rc1(rc1(si)), where i in {1, 2}\n","    Returns:\n","        word_features: List of word ids for lc1(lc1(si)), and rc1(rc1(si)) (use vocab.WORD_NULL if a word does not exist)\n","        pos_features: List of POS ids for lc1(lc1(si)), and rc1(rc1(si)) (use vocab.POS_NULL if a word does not exist)\n","        label_features: List of label ids for lc1(lc1(si)), and rc1(rc1(si)) (use vocab.LABEL_NULL if a word does not exist)\n","    '''\n","    assert i in {1,2}\n","\n","    si = parser_config.stack.get_si(i)\n","    arcs = get_lc(parser_config, si)\n","    if len(arcs) == 0:\n","        l_wf = parser_config.vocab.WORD_NULL\n","        l_pf = parser_config.vocab.POS_NULL\n","        l_lf = parser_config.vocab.LABEL_NULL\n","    else:\n","        lc1_si = arcs[0].dependent\n","        arcs = get_lc(parser_config, lc1_si)\n","        if len(arcs) == 0:\n","            l_wf = parser_config.vocab.WORD_NULL\n","            l_pf = parser_config.vocab.POS_NULL\n","            l_lf = parser_config.vocab.LABEL_NULL\n","        else:\n","            # for lc1(lc1(si))\n","            l_wf = arcs[0].dependent.word_id\n","            l_pf = arcs[0].dependent.pos_id\n","            l_lf = arcs[0].label_id\n","\n","    arcs = get_rc(parser_config, si)\n","    if len(arcs) == 0:\n","        r_wf = parser_config.vocab.WORD_NULL\n","        r_pf = parser_config.vocab.POS_NULL\n","        r_lf = parser_config.vocab.LABEL_NULL\n","    else:\n","        rc1_si = arcs[0].dependent\n","        arcs = get_rc(parser_config, rc1_si)\n","        if len(arcs) == 0:\n","            r_wf = parser_config.vocab.WORD_NULL\n","            r_pf = parser_config.vocab.POS_NULL\n","            r_lf = parser_config.vocab.LABEL_NULL\n","        else:\n","            # for rc1(rc1(si))\n","            r_wf = arcs[0].dependent.word_id\n","            r_pf = arcs[0].dependent.pos_id\n","            r_lf = arcs[0].label_id\n","\n","    word_features = [l_wf, r_wf]\n","    pos_features = [l_pf, r_pf]\n","    label_features = [l_lf, r_lf]\n","    \n","    return word_features, pos_features, label_features\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDtGiNmJiAXI"},"source":["The following function `extract_features(parser_config)` calls each of these functions and returns a list of the 48 total features."]},{"cell_type":"code","metadata":{"id":"OFC1coWRiBHK"},"source":["def extract_features(parser_config): # for both train & inference\n","\n","    word_features, pos_features, label_features = [], [], []\n","\n","    # 1. Get word & pos features for s1, s2, and s3\n","    (x, y) = get_top3_stack_features(parser_config)\n","    word_features, pos_features = word_features + x, pos_features + y\n","\n","\n","    # 2. Get word & pos features for b1, b2, and b3\n","    (x, y) = get_top3_buffer_features(parser_config)\n","    word_features, pos_features = word_features + x, pos_features + y\n","\n","\n","    # 3. Get word & pos & label features for lc1(s1), lc1(s2), lc2(s1), lc2(s2)\n","    (x, y, z) = get_lc1_lc2_features(parser_config, 1)\n","    word_features, pos_features, label_features = word_features + x, pos_features + y, label_features + z\n","\n","    (x, y, z) = get_lc1_lc2_features(parser_config, 2)\n","    word_features, pos_features, label_features = word_features + x, pos_features + y, label_features + z\n","\n","\n","    # 4. Get word & pos & label features for rc1(s1), rc1(s2), rc2(s1), rc2(s2)\n","    (x, y, z) = get_rc1_rc2_features(parser_config, 1)\n","    word_features, pos_features, label_features = word_features + x, pos_features + y, label_features + z\n","\n","    (x, y, z) = get_rc1_rc2_features(parser_config, 2)\n","    word_features, pos_features, label_features = word_features + x, pos_features + y, label_features + z\n","\n","\n","    # 5. Get word & pos & label features for lc1(lc1(s1)), lc1(lc1(s2)), rc1(rc1(s1)), rc1(rc1(s2))\n","    (x, y, z) = get_llc_rrc_features(parser_config, 1)\n","    word_features, pos_features, label_features = word_features + x, pos_features + y, label_features + z\n","\n","    (x, y, z) = get_llc_rrc_features(parser_config, 2)\n","    word_features, pos_features, label_features = word_features + x, pos_features + y, label_features + z\n","\n","\n","    features = word_features + pos_features + label_features\n","    assert len(features) == 48\n","    return features"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SNkhguSo8yHG"},"source":["# Step 3: Dataset & Model\n","\n","Define the Pytorch `Dataset` class as well as the model."]},{"cell_type":"code","metadata":{"id":"jhZI1awMYnRC"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"rFdckWtRrdO7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S6XT_3EgL1LX"},"source":["## Instantiate Dataset\n","\n","Create a Pytorch `Dataset` to be used to feed  training data to the model."]},{"cell_type":"code","metadata":{"id":"PRCHWOA7ykDK"},"source":["class TrainDataset(torch.utils.data.Dataset):\n","    def __init__(self, data, vocab):\n","        self.X = np.array([d[0] for d in data])\n","        self.y = np.array([vocab.tran2id[d[1]] for d in data])\n","    \n","    def __getitem__(self, index):\n","        return self.X[index], self.y[index]\n","\n","    def __len__(self):\n","        return len(self.X)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RMBTW1xXL5nu"},"source":["## Define Model\n","\n","Here we implement the `__init(...)__` and `forward(...)` methods of a feed-forward network. The network will have an embedding layer, a single hidden layer, and an output layer. The `forward(...)` method will take in the features we have extracted from the parser configuration and predict the next parser action."]},{"cell_type":"code","metadata":{"id":"3xauK8678zfh"},"source":["class Model(nn.Module):\n","    def __init__(self, num_embeddings, embed_size, n_features, hidden_size, n_classes, dropout_prob):\n","        '''\n","        Initialize the weights of feed-forward neural network.\n","        Args:\n","            num_embeddings: Number of embedding vectors in embedding layer (int)\n","            embed_size: Size of the embedding vectors in embedding layer (int)\n","            n_features: Number of features in the input to the model (int)\n","            hidden_size: Hidden size (int)\n","            n_classes: Number of classes in output (int)\n","            dropout_prob: Probability of dropout (float)\n","        '''\n","        super(Model, self).__init__()\n","\n","\n","        # Initialize embedding layer \n","        # read documentation for nn.Embedding for thee parameters\n","        self.EmbeddingLayer = nn.Embedding(num_embeddings, embed_size)\n","\n","        # Initialize a linear layer that maps the (concatenated) embeddings to a single vector of size hidden_size\n","        # figure out the parameters: read nn.Linear*(), also refer to step (2) in forward() function\n","        # below, the parameter in_features should be n_features * embed_size;\n","        # The parameter out_features should be \"a single vector of size hidden_size\" as mentioned above\n","        self.LinearLayer1 = nn.Linear(n_features * embed_size, hidden_size)\n","       \n","        # Create a dropout layer with dropout_prob\n","        self.DropoutLayer = nn.Dropout(dropout_prob)\n","\n","        # Initialize a linear layer that maps the hidden vector to the number of output classes\n","        self.LinearLayer2 = nn.Linear(hidden_size, n_classes)\n","\n","    def forward(self, x):\n","        '''\n","        This function predicts the next parser action, given the features extracted from the current parser state.\n","        Inputs:\n","             x: input features, [batch_size, n_features]\n","        Returns:\n","            logits: [batch_size, n_classes]\n","        '''\n","\n","   \n","        # (1) Obtain embedding vectors for the input\n","        #            - Output size: [batch_size, n_features, embed_size]\n","        # reading nn.Embedding documention reveals that the output's first \n","        # two dimensions should be the same as x - [batch_size, n_features], and the 3rd dimension \n","        # should be embed_size, so the output should be [batch_size, n_features, embed_size] \n","        \n","        embedding = self.EmbeddingLayer(x)  #[batch_size, n_features, embed_size]\n","        # added comment - in the following we first permute/swap the 2nd and 3rd dimension \n","        embedding = embedding.permute(0, 2, 1) # [batch_size, embed_size, n_features]\n","        # then use view(batch_size, -1) to concat all n_feature embeddings, each of size embed_size\n","        # the permute performed above is necessary, otherwise it will concat along the n_feature dimension \n","        # in the following the -1 means concat the last two dimentions to one, google and see details \n","        # the call of contiguous() is also necessary \n","        batch_size = embedding.size(dim = 0)\n","        embedding = embedding.contiguous().view(batch_size, -1) #[batch_size, embed_size * n_features]\n","\n","        # (2) Pass the result through the first linear layer and apply ReLU activation\n","        LL1_output = self.LinearLayer1(embedding)  #[batch_size, hidden_size]\n","        LL1_ReLU_output = F.relu(LL1_output)\n","        \n","        # (3) Apply dropout\n","        dropout_output = self.DropoutLayer(LL1_ReLU_output)\n","\n","        #(4) Pass the result through the final linear layer and return its output (do NOT call softmax!)\n","        #            - Output size: [batch_size, n_classes]\n","        output = self.LinearLayer2(dropout_output)\n","\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SV5ia_sDVF46"},"source":["# Step 4: Train Model\n"]},{"cell_type":"code","metadata":{"id":"bBQPrzlUUXXw"},"source":["import math\n","from torch import optim\n","from tqdm.notebook import tqdm\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g-cnEwKKipWv"},"source":["First, read in the training dataset, create training examples, extract features, and instantiate the Pytorch `Dataset`."]},{"cell_type":"code","metadata":{"id":"6_vvizxUIb2B"},"source":["def prepare_data(train_name='train', test_name='test'):\n","\n","    train_set, test_set = load_data()\n","\n","    vocab = Vocabulary(train_set)\n","    vocab.printStats()\n","    print()\n","\n","    train_set = vocab.buildSentences(train_set)\n","    test_set = vocab.buildSentences(test_set)\n","\n","    train_examples = generate_all_training_examples(vocab, train_set, feat_extract=extract_features)\n","\n","    return vocab, train_examples, test_set"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n6Gbj4YT3TJH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646702641210,"user_tz":360,"elapsed":42762,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"71fc3949-75d7-4db1-cec8-cb9c78d4012f"},"source":["if __name__== \"__main__\":\n","    vocab, train_examples, test_data = prepare_data()\n","    train_dataset = TrainDataset(train_examples, vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num. labels: 47\n","Num. transitions (2*n_labels + 1): 95\n","Num. pos: 52\n","Num. words: 16635\n","Num. tokens: 16735\n","\n","Successfully generated training examples for 11888 / 12543 sentences\n","Number of training examples: 373100\n"]}]},{"cell_type":"markdown","metadata":{"id":"gXvJjaQf9jQE"},"source":["The neural network is trained with cross-entropy loss."]},{"cell_type":"code","metadata":{"id":"trW8_LS0Abno"},"source":["def train_model(model, vocab, train_data_loader, optimizer, n_epochs, device):\n","    loss_func = nn.CrossEntropyLoss()\n","    for epoch in range(n_epochs):\n","        start = time.time()\n","        n_batch = 0\n","        total_loss = 0\n","        model.train()      \n","        for train_x, train_y in tqdm(train_data_loader):\n","            optimizer.zero_grad() \n","            train_x = train_x.to(device)\n","            train_y = train_y.to(device)\n","            logits = model(train_x)\n","            loss = loss_func(logits, train_y)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            total_loss +=  loss.item()\n","            n_batch += 1\n","        \n","        print('Epoch:{:2d}/{}\\t Loss: {:.4f} \\t({:.2f}s)'.format(epoch + 1, n_epochs, total_loss / n_batch, time.time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e_6UjiDY91sd"},"source":["Next instantiate the model and an <a href=https://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf>Adagrad</a> optimizer"]},{"cell_type":"code","metadata":{"id":"hK_y2XsJDcS0"},"source":["def count_parameters(model):\n","    \"\"\"\n","    Count number of trainable parameters in the model\n","    \"\"\"\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PXSquloq0-yl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646702650613,"user_tz":360,"elapsed":361,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"2b4fe6b0-1f81-4f17-c1b8-d7f525f8c454"},"source":["if __name__ == \"__main__\":\n","    # HYPERPARAMETERS\n","    BATCH_SIZE = 1024\n","    LEARNING_RATE = 0.01\n","    N_EPOCHS = 10\n","    HIDDEN_SIZE = 300\n","    DROPOUT_PROB = 0.1\n","    EMBED_SIZE = 100\n","    WEIGHT_DECAY = 1e-8\n","    N_EMBEDDINGS = vocab.n_tokens # Do not change!\n","    N_FEATURES = 48 # Do not change!\n","    N_CLASSES = vocab.n_trans # Do not change!\n","    \n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    \n","    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, drop_last=True, shuffle=True)\n","    model = Model(N_EMBEDDINGS, EMBED_SIZE, N_FEATURES, HIDDEN_SIZE, N_CLASSES, DROPOUT_PROB).to(device)\n","    optimizer = optim.Adagrad(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","    \n","    print('The model has {:,d} trainable parameters'.format(count_parameters(model)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 3,142,395 trainable parameters\n"]}]},{"cell_type":"markdown","metadata":{"id":"c9ta0IRdi4_w"},"source":["Run the cell below to train the model."]},{"cell_type":"code","metadata":{"id":"5QJYewzf1BcX","colab":{"base_uri":"https://localhost:8080/","height":519,"referenced_widgets":["88d5ace795d94cc7b3fb42f2373461ca","29b52f5939dc433a8f9af3ddddf45869","412a682cd93b4605be06c069f055cfa0","229cb1ae6d4d4763a28c2dd029731a57","32e89950b28040f18290716dc5256655","f4bda5c04d184492938c9f107c8c5a9f","061233139ce340179110fd7f6fb3b75e","be0fb2bf001c4ee4b47f53b4da9c8d09","099f565746e348ff9332da29a75d27d4","4eabee43b7924067ba1ea264955c414c","fdd18daabd224da4b4eb38ed186e698f","84562433f2d443d19c50d5f25252ba9b","7c8aef0343eb4784ad6eda4c540f4968","7d2ca8b5b9dc47f7b7ddef7eafd30059","f616727957804661878c05e7a68ac379","34a2edb05f4c4e4c82db9a7e512af187","ccd79962fa2e4304bcf5cfb6e73c98c3","fb2c867fe7914b9a871abed5bccd163d","26d0331d277c43ecbf53aab0166cd0ce","dca0e45d58574cf588b6578a6e7a6c55","042f51bfb05f4518a8c7c23df0192d81","92b7abf7683e45e5a3e65df34a489b97","b322f11bfaa1453e975cb014981dd119","bb3b9744c28a4e58b36497bd2cb6cd48","6bcfd693dec34c7ea47bfa7a66e232f2","0611888de65f46fc9ff6e019aeb62189","1c2d166f32984ca8b8d978f7b1a7af73","9e1f9548dac44f45bdf705bf78d5a121","add00cf2857c407bbaaa9b26b7d7a8ab","120ce438072640f7beabb70117d2da7e","07c995fd9ffa4c1c885e81b5a36e2270","afca3e00fec0490eaf765981dcb1102a","f37a0b4016cf4387bbd4691b7c4fcb3d","e02823fea1094a84943eaa57bf4d0c81","d1cbf59bcb7e4f25a109bbcac934bc87","3b3cc769114c4d1e9e04c34f7629b083","7299405560d3480ebfa471e5abba4fec","e0db5931d4b84ff1acc51fc38eb7600d","742de0621b084d44ba2d1a8dc3304ee1","48ef8eaa8b3d4bfd8fdcaa6fd2df4b38","a79a40d62c2c4f5aae764374465d2543","2c60af015c6a423285efaf081a3fc00a","13525c61bae14170bdafc48036467c9d","d59474974392427c88468fbffb22567e","30eaf551b3da4dcf87695c35f0db0140","c2bb0920d23344b2bc6e1c143c8b1366","fc24ce9714604dc4acc79881b1d1c432","d1d4712eb769434ebf06f127b126e73d","bfd6bee118c542fba185877ce67a8a84","481f724cb16d4e219ae8a1ad996ce4de","4f23b007f2234d409b4c173c7f258d66","71a73ae3692d4299951afca809bbc7ea","7f73d40f392346f995d1aecefa9673bb","3dbfd657a1d64d849aaa83b225c26b90","ebd0426328dc412db87c5ba6c000283d","e7dee40edbea4bbd8ce89b26bc05820b","64c9405ed01d438a8502d193edbb9073","913a8aa0b0574272bedba07aec3c6b8d","67cae0a1fe224e3e91215bd450e69a7a","c147c0b7b689461db796c55bb7c421fd","958d5ed3df1845b490f6a8a73cc9e9dd","d83e1b9223d145e3acb8af32c8181750","4b2dbeb319494991a4b27999b778166d","6e919d4021ab421e9df16e2ebcf96e65","2553fe61aeac40338b2592710a9769c5","deca7d770078448b8d0446de325ab15a","b55a520e348346e495d6056770502c4a","6fc0e6bdb1a14bfe99eece3f4ce90750","0e88ab9f35fe4c36bd83476227aca3f2","02532ed5d1d6410a9f1ee9142cefeb0a","fce07caf71c3425da99a0c7ce35446ea","143d051277fe452ab491946c3f584f4d","a70e3165d4f84c5899f1ae74b724d412","f8243cfea5a14a8aa47fd3a8992c2a69","7edd6e8fd24a4cc486ff0b3ab3504d42","ab7139634aca4c068e8562804cf72e56","7dea3650262448fb9ae4676718020e9d","629ef7eec4e842acaf19a25978a7186b","37a6d91fac02411cbda2dc7937348b6e","21e37ffc1d7b4e4e9854ecb05d0fb258","da91e58fd9fb44aa8783dd0859e4d335","6a3d4f589519474382b52fe728f4e91e","221914e60cb74a03814bcc6b698d1d1c","f39378fcd65449209f3a6f3a59dc78e3","4047d96b57954a84ac57096155039eae","3b5f1d695c3b4b7f88c53e26a810f550","a079c2fa3ce846afb81eb2c84afa8176","3e3cceb8256341c4a162a421290075d3","58c0287546034a25b1ba50a15670b52b","485545ddcc8a4b218f49abd0bbed612d","d71ca9dce7694c46b47ee7e81b63c24d","b80d245b9426440bb93368f1bcb31535","b02d6290fc364bd88c4149aaba2e5467","9bf77d245b9b453da9a3d28cbf422804","4125961d04924a95acaf71e8f09589b8","7b4f3f2946d24ae7b46a666fa0509405","88b15e35f1a4447380abaa177e2a7b89","939249fd4f684064bd221faa91ad0892","bd698239122b449fa60dc77f1f005571","36c7723bb1044413a97f885faa4d45c2","1e391461254f4094b4bb72746fc245a8","487200b12c7b4fd9b732c52e84273435","724b7c6274c04af6947822cca66e33f9","461aff7405ca430198d3255a95d6782a","95c63ffdf6464ca29723900bbadc8b81","3643dac1994d463a8e031f772a760cc0","7ad1338759ca405492b441fb203dcb56","1e8a67af146e454d85c3e9c2c19c7700","010b617d71b0457ab9d4ec1fd352cd6d","eacc31d6fca24c53a59275ebe11c5159"]},"executionInfo":{"status":"ok","timestamp":1646703394236,"user_tz":360,"elapsed":737194,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"f5d6cf7e-27b3-4dea-c27e-b1dbbbf8c1e1"},"source":["if __name__=='__main__':\n","    train_model(model, vocab, train_data_loader, optimizer, N_EPOCHS, device)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88d5ace795d94cc7b3fb42f2373461ca","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/364 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1/10\t Loss: 0.7875 \t(75.47s)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84562433f2d443d19c50d5f25252ba9b","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/364 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 2/10\t Loss: 0.2572 \t(73.42s)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b322f11bfaa1453e975cb014981dd119","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/364 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 3/10\t Loss: 0.2145 \t(73.57s)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e02823fea1094a84943eaa57bf4d0c81","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/364 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 4/10\t Loss: 0.1929 \t(73.30s)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30eaf551b3da4dcf87695c35f0db0140","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/364 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 5/10\t Loss: 0.1769 \t(73.30s)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7dee40edbea4bbd8ce89b26bc05820b","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/364 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 6/10\t Loss: 0.1655 \t(73.75s)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b55a520e348346e495d6056770502c4a","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/364 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 7/10\t Loss: 0.1561 \t(73.36s)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"629ef7eec4e842acaf19a25978a7186b","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/364 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 8/10\t Loss: 0.1483 \t(73.43s)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58c0287546034a25b1ba50a15670b52b","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/364 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 9/10\t Loss: 0.1412 \t(73.60s)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36c7723bb1044413a97f885faa4d45c2","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/364 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch:10/10\t Loss: 0.1354 \t(73.87s)\n"]}]},{"cell_type":"markdown","metadata":{"id":"mclt1pAO4Y-X"},"source":["# Step 5: Evaluate Model\n","\n","Now the model has been trained, it can be used to parse unseen sentences from a test set."]},{"cell_type":"markdown","metadata":{"id":"8-0LcUAaGm_y"},"source":["## Select Best Legal Prediction\n","It is possible that the model will predict an illegal action. For example, the model may predict `S` (shift) when the buffer is empty, which is not a valid move. There is no guarantee that this will not happen for an unseen sentence, and so that possibility has to be accounted at inference time.\n","\n","Thus,the <b>legal</b> action with the highest probability for each parser configuration should be returned. "]},{"cell_type":"code","metadata":{"id":"pSDzMZZHsDWO"},"source":["def select_best_legal_action(parser_configs, predictions, n_labels):\n","    '''\n","    Returns the highest probability **legal** prediction for each parser configuration.\n","    Inputs:\n","        parser_configs: list of parser configurations of length N\n","        predictions: np.array of size [N, 2*n_labels + 1]\n","        n_labels: int, the number of labels in our model\n","    Returns:\n","        preds: np.array of length N, containing the indices of the highest probability legal action for each example\n","    '''\n","\n","    assert len(parser_configs) == len(predictions)\n","    for i in range(len(parser_configs)):\n","        if len(parser_configs[i].buffer) == 0:   \n","            # buffer is empty, cannot do shift, so set the prbability for shift to 0\n","            predictions[i][2*n_labels] = 0.0\n","\n","        if len(parser_configs[i].stack) == 1:   \n","            # stack has only one item, ROOT, cannot perform LeftArc or RightArc, so set their probabilitis to 0\n","            predictions[i][:2*n_labels] = [0.0]*2*n_labels\n","        elif len(parser_configs[i].stack) == 2:\n","            # stack has exactly two items, that will be ROOT and another words to its right\n","            # cannot perform LeftArc in this case, so set those probabilitis to 0\n","            predictions[i][:n_labels] = [0.0]*n_labels\n","        # It will never happen that predictions[i] is all 0, since the parser_config with empty buffer \n","        # and a stack with only ROOT will not be passed to this function, this is \"DONE\", inference will halt when that happens      \n","    preds = np.argmax(predictions, axis = 1) \n","\n","    return preds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7-yJnqOu4_bp"},"source":["The following function takes a (trained) model and makes the best legal prediction for a batch of parser configurations."]},{"cell_type":"code","metadata":{"id":"YrDAfdLEwGoU"},"source":["def predict(model, vocab, parser_configs):\n","    '''\n","    Predicts the next transition for each ParserConfiguration in the batch (`parsers`).\n","    '''\n","    model_device = next(model.parameters()).device\n","    \n","    x = np.array([extract_features(p) for p in parser_configs])\n","    x = torch.from_numpy(x).long().to(model_device)\n","    \n","    with torch.no_grad():\n","        pred = model(x)\n","\n","    pred = pred.detach().cpu().numpy()\n","    pred = select_best_legal_action(parser_configs, pred, vocab.n_labels)\n","    actions = [vocab.id2tran[p] for p in pred]\n","    return actions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"76nx_Dp05RJI"},"source":["## Test Set Attachment Score\n","\n","The following functions use the model to parse all sentences in the test set, and compute the attachment score. The <b>unlabeled attachment score</b> is the percentage of arcs in the test set for which the model gets the head correct. The <b>labeled attachment score</b> is the percentage of arcs for which the model gets <em>both</em> the head and the label correct. Thus, attachment score is a number between 0 and 100, and a higher score is better."]},{"cell_type":"code","metadata":{"id":"MjE1uJm3kPvp"},"source":["def run_inference(sentences, model, vocab, batch_size=2000):\n","    '''\n","    Infers the dependency parse for each sentence given a trained model.\n","    '''\n","    N = len(sentences)\n","\n","    # Initialize parser configs\n","    parser_configs = [None] * N\n","    for i in range(N):\n","        sent = sentences[i]\n","        parser_config = ParserConfiguration(sent, vocab)\n","        parser_configs[i] = parser_config\n","\n","    parses_completed = [False] * N # Indicates whether a given parse is completed\n","    \n","    while sum(parses_completed) != N:\n","\n","        # Get batch along with indices\n","        batch_idxes = []\n","        for idx in range(N):\n","            if not parses_completed[idx]: batch_idxes.append(idx)\n","            if len(batch_idxes) == batch_size: break\n","        batch = [parser_configs[idx] for idx in batch_idxes]\n","\n","        # Make prediction, run a parse step, and check for completion\n","        transitions = predict(model, vocab, batch)\n","        for idx, parser, transition in zip(batch_idxes, batch, transitions):\n","            parser.parse_step(transition)\n","            if not parser.buffer.buffer and len(parser.stack.stack) == 1:\n","                parses_completed[idx] = True\n","    \n","    return [parser.dependencies for parser in parser_configs]\n","\n","def transform_to_head_label(dependencies):\n","    head = [-1] * len(dependencies.arcs)\n","    label = [-1] * len(dependencies.arcs)\n","    for dep in dependencies.arcs:\n","        head[dep.dependent.idx-1] = dep.head.idx\n","        label[dep.dependent.idx-1] = dep.label_id  \n","    return head, label\n","\n","\n","def evaluate(model, vocab, dataset, eval_batch_size=5000):\n","    model.eval()\n","    sentences = [x[0] for x in dataset]\n","    gold_dependencies = [x[1] for x in dataset]\n","    pred_dependencies = run_inference(sentences, model, vocab, eval_batch_size)\n","    \n","    UAS, LAS = 0.0, 0.0\n","\n","    all_tokens = 0\n","    \n","    for i in range(len(gold_dependencies)):\n","        assert len(gold_dependencies[i].arcs) == len(pred_dependencies[i].arcs)\n","        \n","        # Get gold answers\n","        gold_head, gold_label = transform_to_head_label(gold_dependencies[i])\n","        \n","        # Get predictions\n","        pred_head, pred_label = transform_to_head_label(pred_dependencies[i])\n","        \n","        assert len(gold_head) == len(pred_head) and len(gold_label) == len(pred_label)\n","        assert -1 not in gold_head + gold_label + pred_head + pred_label\n","\n","        for pred_h, gold_h, pred_l, gold_l  in zip(pred_head, gold_head, pred_label, gold_label):\n","            UAS += (1 if pred_h == gold_h else 0)\n","            LAS += (1 if pred_h == gold_h and pred_l == gold_l else 0)\n","            all_tokens += 1\n","    return UAS / all_tokens * 100, LAS / all_tokens * 100, pred_dependencies"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0mr2pxizujT3"},"source":["Run the following cell to calculate the attachment scores. "]},{"cell_type":"code","metadata":{"id":"MNlTOYpX1dR2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646703610171,"user_tz":360,"elapsed":7420,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"9e7d6806-6355-4f66-cc97-17fee48a87f3"},"source":["if __name__==\"__main__\":\n","    UAS, LAS, test_predictions = evaluate(model, vocab, test_data)\n","    print(\"Test Set Unlabeled Attachment Score:\", UAS)\n","    print(\"Test Set Labeled Attachment Score:\", LAS)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Set Unlabeled Attachment Score: 83.19945920152696\n","Test Set Labeled Attachment Score: 80.67043104819469\n"]}]}]}