{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02 Text Clasification with NN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"widgets":{"application/vnd.jupyter.widget-state+json":{"dca0f30827954ca2877ba3477446b3dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bbae0859c58c428691d1c82708951d83","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_46bfa3fe11094c52936a1ae816c26934","IPY_MODEL_95553186959e4070b7840a6af5e9f9d9","IPY_MODEL_492f798164fb493fb5323ba37edf4fd5"]}},"34213e3a6118454aa479e7b4aee2db24":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_806dcf5210bc464194afed94065f2bd1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f75813394c1349f99b0c74bc606ef843","IPY_MODEL_e127702d4c454fafb96d41e3a6e0b1e3","IPY_MODEL_fd907bb9bdd94dc6b88de2815d015864"]}},"806dcf5210bc464194afed94065f2bd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f75813394c1349f99b0c74bc606ef843":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_09be42da6ea2472984773a7143d01d4f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b2cd2311deb04f88b0e11a13f16591fb"}},"e127702d4c454fafb96d41e3a6e0b1e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_86c9b0f0d0f641d7a0b2b5dda1fb8ca2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":20,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":20,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a727386722d94565a9d7b4600e3fdc4e"}},"fd907bb9bdd94dc6b88de2815d015864":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e280e92c78a24bb98b5dca2b5ca7967d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 20/20 [07:45&lt;00:00, 23.22s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_920d8f7b3922414fa21f373480a82a2c"}},"09be42da6ea2472984773a7143d01d4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b2cd2311deb04f88b0e11a13f16591fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86c9b0f0d0f641d7a0b2b5dda1fb8ca2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a727386722d94565a9d7b4600e3fdc4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e280e92c78a24bb98b5dca2b5ca7967d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"920d8f7b3922414fa21f373480a82a2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e3199e29b304ff399af87547d281df9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_06caf14e6cfc42e693e4a15942145cf4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bf037dfbb8d5457880633eb14342c33c","IPY_MODEL_26873b242a2c4e8aaaaaa2c721669154","IPY_MODEL_2ea40a87b6754f51b098b496f89937b6"]}},"06caf14e6cfc42e693e4a15942145cf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf037dfbb8d5457880633eb14342c33c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_03d728f55d9b4ba09fa68d1a89fb1520","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_254cd25749054363b7da63b83b5a4400"}},"26873b242a2c4e8aaaaaa2c721669154":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_96945065d56a47e58cee7386a45c2140","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":5000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9c17974344134eff86c30b43c22654bd"}},"2ea40a87b6754f51b098b496f89937b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dca9113a57a34d188cbc842c991d656c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5000/5000 [00:21&lt;00:00, 224.54it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_898b3ecffa6d4c5aadeef09e762539e7"}},"03d728f55d9b4ba09fa68d1a89fb1520":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"254cd25749054363b7da63b83b5a4400":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96945065d56a47e58cee7386a45c2140":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9c17974344134eff86c30b43c22654bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dca9113a57a34d188cbc842c991d656c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"898b3ecffa6d4c5aadeef09e762539e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b665db8e5f434150b58ed52a2cbbb2e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_18fe064f7b464f1e89f7e33e24612700","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b8dd72fb4d8741369ce0f7f401f2a344","IPY_MODEL_178ab661efe0432a8dbec20cd57fef31","IPY_MODEL_50093ecf692b42d09a218126ae0ec70b"]}},"18fe064f7b464f1e89f7e33e24612700":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8dd72fb4d8741369ce0f7f401f2a344":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_73d4c23c95a54557b08be17c605275d2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c21b60f7f8f46d6861dc8b1da02f06f"}},"178ab661efe0432a8dbec20cd57fef31":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_52e9f9243a904588a8cd62f0c23a7491","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":15,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":15,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bb847fc0eee844d4879b0cd34df34b7d"}},"50093ecf692b42d09a218126ae0ec70b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4a5025178f4d409c8a8ab63b3a65538b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 15/15 [11:11&lt;00:00, 41.95s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_76c82ad6961e4acba5555c7970f03471"}},"73d4c23c95a54557b08be17c605275d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6c21b60f7f8f46d6861dc8b1da02f06f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52e9f9243a904588a8cd62f0c23a7491":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bb847fc0eee844d4879b0cd34df34b7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a5025178f4d409c8a8ab63b3a65538b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"76c82ad6961e4acba5555c7970f03471":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"pSy-sfxOsclS"},"source":["# Text Clasification with Neural Networks\n","Implement classifiers based on Convolutional Neural Networks (CNN's) and Recurrent Neural Networks (RNN's) to detect the sentiment of movie reviews from the IMDb movie reviews dataset.\n","\n","We recommend runing this notebook on Google Colab instead of your local computer to avoid the hassle of installing necessary Python packages on local machine. Selecting \"GPU\" as the runtime type as this will speed up the training of your models. You can find this by going to <TT>Runtime > Change Runtime Type</TT> and select \"GPU\" from the dropdown menu."]},{"cell_type":"code","metadata":{"id":"EyCOvTRQ1nb-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646664300013,"user_tz":360,"elapsed":9256,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"8a97d908-dbdb-45e4-a479-4f7750ff75fa"},"source":["from collections import defaultdict\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils import data\n","import torchtext \n","import random\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","if __name__=='__main__':\n","    print('Using device:', device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"markdown","metadata":{"id":"zHbJ1-aDsWCG"},"source":["# Step 1: Download the Data\n","First, download the dataset using [torchtext](https://torchtext.readthedocs.io/en/latest/index.html), which is a package that supports NLP for PyTorch. The following cell will get the `train_data` and `test_data`. It also does some basic tokenization.\n","\n","*   To access the list of textual tokens for the *i*th example, use `train_data[i][1]`\n","*   To access the label for the *i*th example, use `train_data[i][0]`\n","\n"]},{"cell_type":"code","metadata":{"id":"dfX3bNby8FYL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646664366560,"user_tz":360,"elapsed":50237,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"69bcb8fa-8b6e-42fb-ef90-bb5b435a5a8b"},"source":["def preprocess(review):\n","    '''\n","    Simple preprocessing function.\n","    '''\n","    res = []\n","    for x in review.split(' '):\n","        remove_beg=True if x[0] in {'(', '\"', \"'\"} else False\n","        remove_end=True if x[-1] in {'.', ',', ';', ':', '?', '!', '\"', \"'\", ')'} else False\n","        if remove_beg and remove_end: res += [x[0], x[1:-1], x[-1]]\n","        elif remove_beg: res += [x[0], x[1:]]\n","        elif remove_end: res += [x[:-1], x[-1]]\n","        else: res += [x]\n","    return res\n","\n","if __name__=='__main__':\n","    train_data = torchtext.datasets.IMDB(root='.data', split='train')\n","    train_data = list(train_data)\n","    train_data = [(x[0], preprocess(x[1])) for x in train_data]\n","    train_data, test_data = train_data[0:10000] + train_data[12500:12500+10000], train_data[10000:12500] + train_data[12500+10000:], \n","\n","    print('Num. Train Examples:', len(train_data))\n","    print('Num. Test Examples:', len(test_data))\n","\n","    print(\"\\nSAMPLE DATA:\")\n","    for x in random.sample(train_data, 5):\n","        print('Sample text:', x[1])\n","        print('Sample label:', x[0], '\\n')\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 84.1M/84.1M [00:08<00:00, 9.47MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Num. Train Examples: 20000\n","Num. Test Examples: 5000\n","\n","SAMPLE DATA:\n","Sample text: ['The', 'DVD', 'version', 'consists', 'of', '2', 'episodes', ',', 'the', 'parricide', 'of', 'Caesar', 'being', 'the', 'juncture', '.', 'In', 'addition', ',', 'the', 'language', 'was', 'Spanish', 'without', 'subtitles', '.', 'Hence', ',', \"it's\", 'hard', 'for', 'me', 'to', 'review', 'in', 'depth', 'this', 'movie', 'because', 'because', 'i', \"didn't\", 'understand', 'what', 'was', 'said.<br', '/><br', '/>Cleopatra', 'being', 'an', 'historic', 'icon', ',', 'the', 'part', 'is', 'very', 'difficult', 'and', 'i', 'found', 'that', 'for', 'a', 'newcomer', ',', 'Leonor', 'Varela', 'just', 'plays', 'fine', '.', 'She', 'is', 'strong-willed', 'but', 'also', 'a', 'very', 'supportive', ',', 'tender', 'soul', 'mate', '.', 'Thimothy', 'Dalton', 'as', 'Caesar', 'is', 'perfect', 'and', 'their', 'romance', 'is', 'the', 'main', 'thing', 'of', 'the', 'first', 'episode', '.', 'So', ',', 'it', 'is', 'not', 'really', 'a', 'documentary', ',', 'nor', 'a', 'peplum', 'but', 'a', 'great', 'love', 'story.<br', '/><br', '/>After', 'the', 'parricide', ',', 'a', 'new', 'lover', 'comes', '(', 'Marc-Antoine', ')', 'but', 'the', 'flavor', 'is', 'gone', ':', 'we', 'remember', 'always', 'our', 'first', 'love', '.', 'So', ',', 'i', 'found', 'the', 'second', 'episode', 'dull', 'and', 'their', 'tragic', 'fate', \"isn't\", 'told', 'powerfully.<br', '/><br', '/>Nonetheless', ',', 'the', 'production', 'is', 'luxurious', ':', 'the', 'sets', 'are', 'big', ',', 'tastefully', 'decorated', ';', 'the', 'Moroccan', 'live', 'location', 'exotic', 'and', 'the', 'wardrobes', 'splendid', '.', 'The', 'producers', 'have', 'a', 'lot', 'of', 'money', 'for', 'sure', ',', 'but', 'they', 'spend', 'nothing', 'on', 'the', 'special', 'effects', '.', 'They', 'are', 'so', 'poor', '(', 'blue', 'screens', ',', 'ships', ',', 'Sphinx', ')', 'that', \"it's\", 'funny.<br', '/><br', '/>Finally', ',', 'I', 'would', 'like', 'very', 'much', 'to', 'hear', 'it', 'in', 'french', 'or', 'English', 'to', 'make', 'a', 'definitive', 'opinion', 'about', 'this', 'two', 'movies', '.']\n","Sample label: neg \n","\n","Sample text: ['This', 'has', 'some', 'excellent', 'spots', 'but', 'the', 'length', 'of', 'the', 'film', 'can', 'not', 'sustain', 'the', 'wafer', 'thin', 'plot', '.', 'It', 'is', 'another', 'sailors', 'on', 'leave', 'film', ',', 'zippier', 'than', \"Astaire's\", \"'\", 'Follow', 'the', 'Fleet', \"'\", 'but', 'not', 'as', 'good', 'as', \"'\", 'On', 'The', \"Town'\", '.', '<br', '/><br', '/>Kathryn', 'Grayson', 'is', 'bland', 'but', 'Kelly', 'and', 'Sinatra', 'work', 'well', 'together', '.', 'Their', \"'\", 'If', 'you', 'Knew', 'Susie', \"'\", 'number', 'is', 'hilarious', 'as', 'they', 'make', 'up', 'the', 'song', 'as', 'they', 'sing', 'it', '.', \"'\", 'I', 'Begged', 'Her', \"'\", 'is', 'also', 'fun', 'with', 'Sinatra', 'showing', 'how', 'adept', 'he', 'was', 'at', 'hoofing', '.', \"Sinatra's\", 'solo', 'songs', 'are', 'dull', 'and', 'seem', 'to', 'be', 'inserted', 'to', 'show', 'off', 'his', 'singing', 'rather', 'than', 'as', 'part', 'of', 'the', 'story', '.', 'Fortunately', 'there', 'are', 'accomplished', 'supporting', 'actors', 'like', 'Grady', 'Sutton', ',', 'Rags', 'Ragland', ',', 'Carlos', 'Ramirez', 'and', 'Pamela', 'Britton', 'and', 'an', 'unlikely', 'but', 'impertubable', 'Jose', 'Iturbi', 'as', 'himself', ',', 'to', 'keep', 'one', 'watching.<br', '/><br', '/>Kelly', 'is', 'the', 'star', 'of', 'the', 'film', ',', 'although', 'third', 'billed', 'and', 'it', 'is', 'interesting', 'to', 'see', 'him', 'interact', 'with', 'children', ',', 'which', 'Astaire', 'never', 'did', '.', 'Dean', 'Stockwell', 'plays', 'a', 'child', 'who', 'wants', 'to', 'be', 'in', 'the', 'navy', 'and', 'latches', 'on', 'to', 'the', 'Kelly', 'character', '.', 'He', 'also', 'visit', 'a', 'school', 'resulting', 'in', 'him', 'telling', 'the', 'children', 'a', 'fictitious', 'story', 'of', 'his', 'life', 'in', 'the', 'Pomeranian', '(', '!)navy', 'which', 'leads', 'to', 'his', 'wonderful', 'dance', 'with', 'an', 'animated', 'Jerry', 'Mouse', '.', 'In', 'another', 'scene', 'he', 'dances', 'a', 'charming', 'Mexican', 'Hat', 'Dance', 'with', 'a', 'sublimely', 'grave', 'faced', 'little', 'girl', ',', 'Sharon', 'McManus', ',', 'that', 'is', 'entrancing', 'and', 'sweet', '.', '<br', '/><br', '/>Very', 'pleasant', 'then', 'but', 'a', 'bit', 'too', 'long', '.', 'A', 'taster', 'of', 'better', 'musicals', 'to', 'come', '.']\n","Sample label: pos \n","\n","Sample text: ['I', 'must', 'admit', ',', 'I', 'was', 'one', 'of', 'the', 'skeptics', 'who', 'prematurely', 'judged', 'this', 'show', 'before', 'relatively', 'any', 'information', 'was', 'disseminated', 'about', 'it', '.', 'I', 'determined', 'that', 'it', 'was', 'going', 'to', 'be', 'a', 'cheap', 'spin-off', 'guided', 'by', 'Ronald', 'D', '.', 'Moore', 'wielding', 'the', 'retcon-wand.<br', '/><br', '/>I', 'was', 'wrong!<br', '/><br', '/>The', 'pilot', 'leaves', 'an', 'excellent', 'impression', 'upon', 'the', 'viewers', '.', 'The', 'accessibility', 'is', 'marvelous', '!', 'Of', 'course', ',', 'seasoned', 'BSG', 'veterans', 'will', 'find', 'themselves', 'immersed', 'in', 'the', 'plot', ',', 'which', 'is', 'focused', 'on', 'the', 'development', 'of', 'the', 'Cylons', 'before', 'the', 'first', 'War', '.', '(', '58', 'years', 'before', 'the', 'events', 'of', 'the', 'BSG', 'pilot)', '.', 'The', 'pilot', 'also', 'allows', 'for', 'newcomers', ',', 'clearly', 'presenting', 'its', 'plot', 'and', 'ideas', 'in', 'the', 'first', 'part', 'of', 'the', 'episode.<br', '/><br', \"/>Don't\", 'be', 'mistaken', ':', '\"', 'Caprica', '\"', 'is', 'not', 'BSG', '.', 'We', 'are', 'presented', 'with', 'an', 'immersive', ',', 'cerebral', 'drama', 'dotted', 'by', 'provocative', ',', 'daring', ',', 'and', 'controversial', 'ideas', '.', '<br', '/><br', '/>The', 'casting', 'maintains', \"BSG's\", 'standards', ';', 'Stoltz', 'and', 'Morales', 'are', 'simply', 'astounding', '.', 'Morales', \"'\", 'portrayal', 'of', 'Joseph', 'Adama', ',', 'inspired', 'by', 'Olmos', \"'\", 'portrayal', 'of', 'William', ',', 'gives', 'a', 'wonderful', 'glimpse', 'of', \"William's\", 'heroic', 'father', '.', \"Stoltz's\", 'portrayal', 'of', 'Dr', '.', 'Graystone', 'provokes', 'a', 'lot', 'of', 'thinking', 'and', 'questions.<br', '/><br', '/>If', 'the', 'quality', 'of', 'the', 'pilot', 'is', 'any', 'indication', 'of', \"what's\", 'yet', 'to', 'come', ',', 'RDM', 'and', 'the', 'creative', 'team', 'are', 'set', 'to', 'continue', \"BSG's\", 'legacy', 'of', 'first-rate', 'television', 'programming', 'with', 'another', 'masterfully', 'created', 'television', 'masterpiece', '.']\n","Sample label: pos \n","\n","Sample text: ['Whether', 'this', 'movie', 'is', 'propaganda', 'or', 'not', '(', 'I', 'firmly', 'believe', 'it', 'is', 'not)', ',', 'it', 'really', 'shows', 'the', 'power', 'of', 'Media', '.', 'The', 'importance', 'of', 'this', 'documentary', 'is', 'not', 'to', 'show', 'how', 'good', 'of', 'a', 'man', 'Chavez', 'is', '.', 'It', 'is', 'really', 'to', 'demonstrate', 'the', 'way', 'the', 'Bolivarians', 'saw', 'how', 'it', 'happened', ',', 'the', 'Chavez', 'way', 'of', 'seeing', 'it', '.', 'Although', 'it', 'may', 'seem', 'wrong', 'and', 'bias', 'to', 'support', 'a', 'film', '', ',', 'I', 'think', 'the', 'point', 'of', 'view', 'shown', 'in', 'the', 'movie', 'is', 'utterly', 'legitimate', '.', 'The', 'Venezuelian', 'people', 'via', 'the', 'private', 'media', 'corporation', 'of', 'Venezuela', 'only', 'saw', 'a', 'one', 'side', 'perspective', 'of', 'the', 'coup', ',', 'the', 'Neo-Liberal', 'side', '.', 'This', 'movie', 'shows', 'us', 'the', 'way', 'the', 'Bolivarians', 'saw', 'it', '', '.', 'Call', 'it', 'propaganda', '', ',', 'I', 'say', \"it's\", 'a', 'judgment', 'call', 'on', 'your', 'part', '.']\n","Sample label: pos \n","\n","Sample text: ['Where', 'to', 'begin', '?', 'How', 'best', 'to', 'describe', 'just', 'how', 'awful', 'this', 'movie', 'is???<br', '/><br', \"/>Let's\", 'start', 'with', 'the', 'campy', 'hick', 'humor', '.', 'It', \"isn't\", 'very', 'funny', '.', 'Add', 'a', 'bunch', 'of', 'musicians', 'impersonating', 'actors', '-', 'Meat', 'Loaf', 'is', 'horrible', 'and', 'Deborah', 'Harry', 'is', 'even', 'worse', '.', 'Pity', 'poor', 'Art', 'Carney', ',', 'who', 'should', 'have', 'known', 'better', 'than', 'to', 'do', 'this', 'movie.<br', '/><br', '/>And', 'then', 'there', 'is', 'the', 'plot', '.', 'A', 'roadie', 'whose', 'life', 'goal', 'is', 'to', 'work', 'an', 'Alice', 'Cooper', 'show', 'meets', 'a', 'girl', 'whose', 'life', 'goal', 'is', 'to', 'be', 'a', 'groupie', 'for', 'Alice', 'Cooper', '.', 'At', 'least', 'they', 'get', 'what', 'they', 'want...<br', '/><br', '/>And', 'then', ',', 'just', 'when', 'the', 'movie', 'should', 'end', ',', 'they', \"can't\", 'come', 'up', 'with', 'a', 'more', 'plausible', 'last', 'scene', 'than', 'a', '-', 'well', ',', 'I', \"won't\", 'ruin', 'it', 'for', 'you', 'if', 'you', 'really', 'want', 'to', 'see', 'the', 'movie.<br', '/><br', '/>There', 'are', 'certain', 'actors', 'that', 'let', 'you', 'know', 'that', 'this', 'is', 'going', 'to', 'be', 'a', '\"', 'B', '\"', 'movie', 'or', 'perhaps', 'worse', '.', 'Gailard', 'Sartain', 'is', 'one', 'of', 'them', 'for', 'me', '-', 'and', 'he', 'has', 'a', 'more', 'prominent', 'role', '.', \"That's\", 'a', 'sure', 'sign', 'that', 'the', 'movie', 'probably', \"won't\", 'be', 'very', 'good', '.', 'If', 'nothing', 'else', ',', 'the', 'movie', 'lives', 'up', 'to', 'the', 'low', 'expectations', '-', 'even', 'exceeds', 'them', 'by', 'being', 'worse', 'than', 'poor.<br', '/><br', \"/>Let's\", 'just', 'say', 'this', '.', 'This', 'is', 'the', 'movie', 'against', 'which', 'all', 'bad', 'movies', 'are', 'compared', '.', 'And', 'none', 'are', 'worse', 'than', 'Roadie', '.']\n","Sample label: neg \n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"_kfg8RcyskyU"},"source":["# Step 2: Create Dataloader\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lvFX-iX5oq7T"},"source":["## Define the Dataset Class\n","\n","The dataset contains the tokenized data for the model. The following functions will be implemented: \n","\n","*   <b>` build_dictionary(self)`:</b>  Creates the dictionaries `idx2word` and `word2idx`. Represent each word in the dataset with a unique index, and keep track of this in these dictionaries. Use the hyperparameter `threshold` to control which words appear in the dictionary: a training word’s frequency should be `>= threshold` to be included in the dictionary.\n","\n","* <b>`convert_text(self)`:</b> Converts each review in the dataset to a list of indices, given by `word2idx` dictionary. Store this in the `textual_ids` variable, and the function does not return anything. If a word is not present in the  `word2idx` dictionary, use the `<UNK>` token for that word. Be sure to append the `<END>` token to the end of each review.\n","\n","*   <b>` get_text(self, idx) `:</b> Return the review at `idx` in the dataset as an array of indices corresponding to the words in the review. If the length of the review is less than `max_len`, pad the review with the `<PAD>` character up to the length of `max_len`. If the length is greater than `max_len`, then only return the first `max_len` words. The return type should be `torch.LongTensor`.\n","\n","*   <b>`get_label(self, idx) `</b>: Return `1` if the label for `idx` in the dataset is `positive`, `0` if it is `negative`. The return type should be `torch.LongTensor`.\n","\n","*  <b> ` __len__(self) `:</b> Return the total number of reviews in the dataset as an `int`.\n","\n","*   <b>` __getitem__(self, idx)`:</b> Return the (padded) text, and the label. The return type for both these items should be `torch.LongTensor`.\n","\n","\n","<b>Note:</b> convert all words to lower case in the functions."]},{"cell_type":"code","metadata":{"id":"1irMn3LX2YDB"},"source":["PAD = '<PAD>'\n","END = '<END>'\n","UNK = '<UNK>'\n","\n","class TextDataset(data.Dataset):\n","    def __init__(self, examples, split, threshold, max_len, idx2word=None, word2idx=None):\n","\n","        self.examples = examples\n","        assert split in {'train', 'val', 'test'}\n","        self.split = split\n","        self.threshold = threshold\n","        self.max_len = max_len\n","\n","        # Dictionaries\n","        self.idx2word = idx2word\n","        self.word2idx = word2idx\n","        if split == 'train':\n","            self.build_dictionary()\n","        self.vocab_size = len(self.word2idx)\n","        \n","        # Convert text to indices\n","        self.textual_ids = [] # should this be a 2-D array indexed by ith example's review and also each idx in the ith review?\n","        self.convert_text()\n","\n","    \n","    def build_dictionary(self): \n","        '''\n","        Build the dictionaries idx2word and word2idx. This is only called when split='train', as these\n","        dictionaries are passed in to the __init__(...) function otherwise. Be sure to use self.threshold\n","        to control which words are assigned indices in the dictionaries.\n","        Returns nothing.\n","        '''\n","        assert self.split == 'train'\n","        \n","        # Don't change this\n","        self.idx2word = {0:PAD, 1:END, 2: UNK}\n","        self.word2idx = {PAD:0, END:1, UNK: 2}\n","\n","        # Count the frequencies of all words in the training data (self.examples)\n","        # Assign idx (starting from 3) to all words having word_freq >= self.threshold\n","        # Make sure to call word.lower() on each word to convert it to lowercase\n","        temp_dic = {}\n","        \n","        # In the following, the [1] after [i] indicate the list of textual tokens for the ith example as mentioned in\n","        # Step 1: Download the Data: To access the list of textual tokens for the ith example, use train_data[i][1]\n","\n","        for i in range(len(self.examples)):\n","            for j in range(len(self.examples[i][1])):\n","                token_lower_case = self.examples[i][1][j].lower()\n","                # save the lower case version\n","                self.examples[i][1][j] = token_lower_case\n","                # increment the count \n","                temp_dic[token_lower_case] = temp_dic.get(token_lower_case, 0) + 1\n","        \n","        # starting idx from 3\n","        idx = 3\n","        for token in temp_dic.keys():\n","            if temp_dic[token] >= self.threshold:\n","                self.idx2word[idx] = token\n","                self.word2idx[token] = idx\n","                idx += 1\n","    \n","    def convert_text(self):\n","        '''\n","        Convert each review in the dataset (self.examples) to a list of indices, given by self.word2idx.\n","        Store this in self.textual_ids; returns nothing.\n","        '''\n","\n","        # Remember to replace a word with the <UNK> token if it does not exist in the word2idx dictionary.\n","        # Remember to append the <END> token to the end of each review.\n","        # Note: the two lines of comments above this line is implemented in get_text() funtion\n","        for i in range(len(self.examples)):\n","            self.textual_ids.append(self.get_text(i))\n","\n","\n","    def get_text(self, idx):\n","        '''\n","        Return the review at idx as a long tensor (torch.LongTensor) of integers corresponding to the words in the review.\n","        You may need to pad as necessary (see above).\n","        '''\n","        # intialize all of text id list with the value 0 of max length defined as self.max_len\n","        # value 0 is the idx of PAD defined above. Also refer to the following statement we quoted from above \n","        # \"you should pad the review with the <PAD> character up to the length of max_len\"\n","        txt_id_list = [0] * self.max_len\n","        # In the following,  the index [1] is used to access texual tokens, \n","        # refer to statement in step 1 \"To access the list of textual tokens for the ith example, use train_data[i][1]\"\n","        review_text = self.examples[idx][1] \n","\n","        review_len = min(self.max_len, len(review_text)) \n","        for i in range(review_len):\n","            # Note: in the following if a token is not found, the get() returns a default value of 2 \n","            # which is the idx of UNK as defined above --- self.word2idx = {PAD:0, END:1, UNK: 2}\n","            # Quoted from step 2: If a word is not present in the word2idx dictionary, you should use the <UNK> token for that word\n","            txt_id_list[i] = self.word2idx.get(review_text[i],2)\n","        # The following is doing as quoted from Step 2: \"Be sure to append the <END> token to the end of each review.\"\n","        # And the index value of END is \"1\", and the position of the end of the list is self.max_len-1, as assign value \"1\"  to it\n","        txt_id_list[self.max_len-1] = 1\n","\n","        return torch.LongTensor(txt_id_list)\n","    \n","    def get_label(self, idx):\n","        '''\n","        This function should return the value 1 if the label for idx in the dataset is 'positive', \n","        and 0 if it is 'negative'. The return type should be torch.LongTensor.\n","        '''\n","        # Note: in the following, the [0] after [idx] indicate the label for the ith example as mentioned in\n","        # Step 1: Download the Data: To access the label for the ith example, use train_data[i][0]\n","\n","        # The label for \"positive\" is \"pos\", label for \"negative\" is \"neg\", so DO NOT USE\n","        # if self.examples[idx][0] == \"positive\" in the following, otherwise, all examples\n","        # will return a \"negative\" label, and the train and test accuracy will all be 100%, abnormal\n","        if self.examples[idx][0] == \"pos\":\n","            return torch.squeeze(torch.LongTensor([1]))\n","        else:\n","            return torch.squeeze(torch.LongTensor([0]))\n","\n","    def __len__(self):\n","        '''\n","        Return the number of reviews (int value) in the dataset\n","        '''\n","        return len(self.examples)\n","    \n","    def __getitem__(self, idx):\n","        '''\n","        Return the review, and label of the review specified by idx.\n","        '''\n","\n","        text_ids = self.get_text(idx)\n","        label = self.get_label(idx)\n","        return text_ids, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HSxpGXj6ml9N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646664394066,"user_tz":360,"elapsed":5998,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"fabed2f2-9f81-4c2a-e0b3-f416012a86ec"},"source":["if __name__=='__main__':\n","    # Sample item\n","    Ds = TextDataset(train_data, 'train', threshold=10, max_len=150)\n","    print('Vocab size:', Ds.vocab_size)\n","\n","    text, label = Ds[random.randint(0, len(Ds))]\n","    print('Example text:', text)\n","    print('Example label:', label)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocab size: 19002\n","Example text: tensor([   41,   458,    49,   472,     3,   536, 13647,    27,    41,  8372,\n","          391,    91,    17,    19,  2484,    24,   233,  2498,  5120,   932,\n","           24,    17,   633,  1146,    70,  4269,   934,   127,    41,  7450,\n","           60,    24,  7292, 14305,  1512,   863,  2610,   105,    74,  2526,\n","         4384,    11,  1048,    38,  1320,    38,    91,  1569,   339,   283,\n","           24,   724, 14306,    38,    13,   969,    38,   103,   129,    41,\n","         3238,  6920,   157,    15,   224,    13,  3243,   837,    11, 11526,\n","         6468,    22,    13,  5708,  7414,   351,    24,    50,    12,    11,\n","          124,  1133,    38, 13647,  2934,   105,   124,  3018,    24,   232,\n","           55,   302,  3302,    50,    41,    20,   323,   969,    38,   511,\n","          105,    41,  1965,  1133,    24,   732,    55,    41,   136,   551,\n","           24,     2,     2,    38,  5365,  3783, 13834,    38, 10838,     2,\n","           38,    91,     2,     2,  4475,   325,    13,   937,   105,  2335,\n","           91,   825,   335,  1259,    88,    13,   362,   167, 10613, 15157,\n","          256,    24,   922,   410,    34,    49,   618,  1327,   522,     1])\n","Example label: tensor(1)\n"]}]},{"cell_type":"markdown","metadata":{"id":"e_4FFhulaAod"},"source":["# Step 3: Train a Convolutional Neural Network (CNN)"]},{"cell_type":"markdown","metadata":{"id":"VcSKydlClwOC"},"source":["## Define the CNN Mode\n","Define a convolutional neural network for text classification.\n","In particular, pay attention to the desired tensor shapes, print them out if necessary for debugging. Also refer to PyTorch documentation for the modules & functions to be used, since they describe input and output dimensions."]},{"cell_type":"code","metadata":{"id":"0ztuy2hUaAof"},"source":["class CNN(nn.Module):\n","    def __init__(self, vocab_size, embed_size, out_channels, filter_heights, stride, dropout, num_classes, pad_idx):\n","        super(CNN, self).__init__()\n","        \n","        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n","        #   to represent the words in your vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n","        #  Note: pad_idx = 0, refer to the defintion above  self.word2idx = {PAD:0, END:1, UNK: 2}\n","        self.EmbeddingLayer = nn.Embedding(vocab_size, embed_size)\n","\n","        # Define multiple Convolution layers (nn.Conv2d) with filter (kernel) size [filter_height, embed_size] based on \n","        #   different filter_heights.\n","        # Input channels will be 1 and output channels will be out_channels (these many different filters will be trained \n","        #   for each convolution layer)\n","        # Note: even though the conv layers are nn.Conv2d, we are doing a 1d convolution since we are only moving the filter \n","        #   in one direction\n","\n","        # Note: in the following \"1\" is the input channels as mentioned above\n","        # 3 is the num_of_cnn_layers variable used below, 3 CNN layers are side by side, not stacked, \n","        self.conv1 = nn.Conv2d(1, out_channels, [filter_heights[0], embed_size])\n","        self.conv2 = nn.Conv2d(1, out_channels, [filter_heights[1], embed_size])\n","        self.conv3 = nn.Conv2d(1, out_channels, [filter_heights[2], embed_size])\n","\n","        # Create a dropout layer (nn.Dropout) using dropout\n","        self.DropoutLayer = nn.Dropout()\n","\n","        # Define a linear layer (nn.Linear) that consists of num_classes units \n","        # and takes as input the concatenated output for all cnn layers (out_channels * num_of_cnn_layers units)\n","        # Note: in the following \"3\" is the num_of_cnn_layers, see a comment above\n","        self.LinearLayer = nn.Linear(out_channels * 3, num_classes)\n","\n","\n","    def forward(self, texts):\n","        \"\"\"\n","        texts: LongTensor [batch_size, max_len]\n","        \n","        Returns output: Tensor [batch_size, num_classes]\n","        \"\"\"\n","\n","        # Pass texts through the embedding layer to convert from word ids to word embeddings\n","        #   Resulting: shape: [batch_size, max_len, embed_size]\n","        embeddings  = self.EmbeddingLayer(texts)\n","\n","        # Input to conv should have 1 channel. Take a look at torch's unsqueeze() function\n","        #   Resulting shape: [batch_size, 1, MAX_LEN, embed_size]\n","       \n","        # Pass these texts to each of the conv layers and compute their output as follows:\n","        #   The cnn output will have shape [batch_size, out_channels, *, 1] where * depends on filter_height and stride\n","        #   Convert to shape [batch_size, out_channels, *] (see torch's squeeze() function)\n","        #   Apply non-linearity on it (F.relu() is a commonly used one)\n","        #   Take the max value across last dimension to have shape [batch_size, out_channels]\n","        # Concatenate outputs from all the cnn's [batch_size, (out_channels*num_of_cnn_layers)]\n","        #\n","        Conv1_Output = self.conv1(torch.unsqueeze(embeddings, 1))\n","        Conv2_Output = self.conv2(torch.unsqueeze(embeddings, 1))\n","        Conv3_Output = self.conv3(torch.unsqueeze(embeddings, 1))\n","\n","        Conv1_Output_Converted = torch.squeeze(Conv1_Output, 3)\n","        Conv2_Output_Converted = torch.squeeze(Conv2_Output, 3)\n","        Conv3_Output_Converted = torch.squeeze(Conv3_Output, 3)\n","\n","        Relu1 = F.relu(Conv1_Output_Converted)\n","        Relu2 = F.relu(Conv2_Output_Converted)\n","        Relu3 = F.relu(Conv3_Output_Converted)\n","\n","        Max1 = torch.max(Relu1, 2)[0]\n","        Max2 = torch.max(Relu2, 2)[0]\n","        Max3 = torch.max(Relu3, 2)[0]\n","\n","        CNNOutputConcat = torch.cat([Max1, Max2, Max3], dim = 1)\n","\n","        # Let's summarize what has been done so far:\n","        #   Since each cnn is of different filter_height, it will look at different number of words at a time\n","        #     So, a filter_height of 3 means the cnn looks at 3 words (3-grams) at a time and tries to extract some information from it\n","        #   Each cnn will learn out_channels number of features from the words it sees at a time\n","        #   Then a non-linearity is applied and the max value for all channels is taken\n","        #     We are essentially trying to find important n-grams from the entire text\n","        # Everything happens on a batch simultaneously hence we have that additional batch_size as the first dimension\n","\n","        # Apply dropout\n","        DropoutCNNConcat = self.DropoutLayer(CNNOutputConcat)\n","\n","        # Pass the output through the linear layer and return its output \n","        #   Resulting shape: [batch_size, num_classes]\n","\n","        output = self.LinearLayer(DropoutCNNConcat) \n","\n","        # NOTE: Do not apply a sigmoid or softmax to the final output - done in training method!\n","\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FupiBIfasCu_"},"source":["## Train CNN Model\n","\n","First, initialize the train and test <b>dataloaders</b>. A dataloader is responsible for providing batches of data to the model."]},{"cell_type":"code","metadata":{"id":"J2QYl334n9ON"},"source":["if __name__=='__main__':\n","    THRESHOLD = 5 # Don't change this\n","    MAX_LEN = 100 # Don't change this\n","    BATCH_SIZE = 32 # Feel free to try other batch sizes\n","\n","    train_Ds = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n","    train_loader = torch.utils.data.DataLoader(train_Ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n","\n","    test_Ds = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_Ds.idx2word, train_Ds.word2idx)\n","    test_loader = torch.utils.data.DataLoader(test_Ds, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AvsctopWmeoY"},"source":["Then the following function takes the model and trains it on the data.\n"]},{"cell_type":"code","metadata":{"id":"LD-Jj2rUFOzr"},"source":["from tqdm.notebook import tqdm\n","\n","def train_model(model, num_epochs, data_loader, optimizer, criterion):\n","    print('Training Model...')\n","    model.train()\n","    for epoch in tqdm(range(num_epochs)):\n","        epoch_loss = 0\n","        epoch_acc = 0\n","        for texts, labels in data_loader:\n","            texts = texts.to(device) # shape: [batch_size, MAX_LEN]\n","            labels = labels.to(device) # shape: [batch_size]\n","\n","            optimizer.zero_grad()\n","\n","            output = model(texts)\n","            acc = accuracy(output, labels)\n","            \n","            loss = criterion(output, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        print('[TRAIN]\\t Epoch: {:2d}\\t Loss: {:.4f}\\t Train Accuracy: {:.2f}%'.format(epoch+1, epoch_loss/len(data_loader), 100*epoch_acc/len(data_loader)))\n","    print('Model Trained!\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FyIZS0WUhFA6"},"source":["Here are some other helper functions we will need."]},{"cell_type":"code","metadata":{"id":"zVP2scuyhG5f"},"source":["\n","def count_parameters(model):\n","    \"\"\"\n","    Count number of trainable parameters in the model\n","    \"\"\"\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","def accuracy(output, labels):\n","    \"\"\"\n","    Returns accuracy per batch\n","    output: Tensor [batch_size, n_classes]\n","    labels: LongTensor [batch_size]\n","    \"\"\"\n","    preds = output.argmax(dim=1) # find predicted class\n","    correct = (preds == labels).sum().float() # convert into float for division \n","    acc = correct / len(labels)\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YjvX5c6Isw9e"},"source":["Now instantiate the model, with some hyperparameters values, can play around with them."]},{"cell_type":"code","metadata":{"id":"M5UtdjGDuBty","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646664532876,"user_tz":360,"elapsed":9881,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"bc32c18e-14c6-4dc5-e1f2-50cc6bd43562"},"source":["if __name__=='__main__':\n","    cnn_model = CNN(vocab_size = train_Ds.vocab_size, # Don't change this\n","                embed_size = 128, \n","                out_channels = 64, \n","                filter_heights = [2, 3, 4], \n","                stride = 1, \n","                dropout = 0.5, \n","                num_classes = 2, # Don't change this\n","                pad_idx = train_Ds.word2idx[PAD]) # Don't change this\n","\n","    # Put the model on the device (cuda or cpu)\n","    cnn_model = cnn_model.to(device)\n","    \n","    print('The model has {:,d} trainable parameters'.format(count_parameters(cnn_model)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 3,879,746 trainable parameters\n"]}]},{"cell_type":"markdown","metadata":{"id":"SeHpqw6zvkhI"},"source":["Next, we create the **criterion**, which is the loss function: it is a measure of how well the model matches the empirical distribution of the data. We use cross-entropy loss (https://en.wikipedia.org/wiki/Cross_entropy).\n","\n","We also define the **optimizer**, which performs gradient descent. We use the Adam optimizer (https://arxiv.org/pdf/1412.6980.pdf), which has been shown to work well on these types of models."]},{"cell_type":"code","metadata":{"id":"FoeyQL4PoNoH"},"source":["if __name__=='__main__':    \n","    LEARNING_RATE = 5e-4 # Feel free to try other learning rates\n","\n","    # Define the loss function\n","    criterion = nn.CrossEntropyLoss().to(device)\n","\n","    # Define the optimizer\n","    optimizer = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RopLfAJ9wOHN"},"source":["Finally, we can train the model."]},{"cell_type":"code","metadata":{"id":"lPOs1FifoNoN","colab":{"base_uri":"https://localhost:8080/","height":467,"referenced_widgets":["34213e3a6118454aa479e7b4aee2db24","806dcf5210bc464194afed94065f2bd1","f75813394c1349f99b0c74bc606ef843","e127702d4c454fafb96d41e3a6e0b1e3","fd907bb9bdd94dc6b88de2815d015864","09be42da6ea2472984773a7143d01d4f","b2cd2311deb04f88b0e11a13f16591fb","86c9b0f0d0f641d7a0b2b5dda1fb8ca2","a727386722d94565a9d7b4600e3fdc4e","e280e92c78a24bb98b5dca2b5ca7967d","920d8f7b3922414fa21f373480a82a2c"]},"executionInfo":{"status":"ok","timestamp":1646660280291,"user_tz":360,"elapsed":465602,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"e6ccbb59-f014-41a4-c617-b76f60505604"},"source":["if __name__=='__main__':    \n","    N_EPOCHS = 20 # Feel free to change this\n","    \n","    # train model for N_EPOCHS epochs\n","    train_model(cnn_model, N_EPOCHS, train_loader, optimizer, criterion)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Model...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34213e3a6118454aa479e7b4aee2db24","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[TRAIN]\t Epoch:  1\t Loss: 0.6920\t Train Accuracy: 59.05%\n","[TRAIN]\t Epoch:  2\t Loss: 0.5919\t Train Accuracy: 68.05%\n","[TRAIN]\t Epoch:  3\t Loss: 0.5366\t Train Accuracy: 73.09%\n","[TRAIN]\t Epoch:  4\t Loss: 0.4968\t Train Accuracy: 75.78%\n","[TRAIN]\t Epoch:  5\t Loss: 0.4510\t Train Accuracy: 79.01%\n","[TRAIN]\t Epoch:  6\t Loss: 0.4083\t Train Accuracy: 81.47%\n","[TRAIN]\t Epoch:  7\t Loss: 0.3648\t Train Accuracy: 83.78%\n","[TRAIN]\t Epoch:  8\t Loss: 0.3239\t Train Accuracy: 85.89%\n","[TRAIN]\t Epoch:  9\t Loss: 0.2804\t Train Accuracy: 88.17%\n","[TRAIN]\t Epoch: 10\t Loss: 0.2374\t Train Accuracy: 90.05%\n","[TRAIN]\t Epoch: 11\t Loss: 0.1997\t Train Accuracy: 91.94%\n","[TRAIN]\t Epoch: 12\t Loss: 0.1681\t Train Accuracy: 93.32%\n","[TRAIN]\t Epoch: 13\t Loss: 0.1428\t Train Accuracy: 94.42%\n","[TRAIN]\t Epoch: 14\t Loss: 0.1107\t Train Accuracy: 95.89%\n","[TRAIN]\t Epoch: 15\t Loss: 0.0920\t Train Accuracy: 96.61%\n","[TRAIN]\t Epoch: 16\t Loss: 0.0816\t Train Accuracy: 96.89%\n","[TRAIN]\t Epoch: 17\t Loss: 0.0674\t Train Accuracy: 97.60%\n","[TRAIN]\t Epoch: 18\t Loss: 0.0586\t Train Accuracy: 97.88%\n","[TRAIN]\t Epoch: 19\t Loss: 0.0482\t Train Accuracy: 98.33%\n","[TRAIN]\t Epoch: 20\t Loss: 0.0445\t Train Accuracy: 98.44%\n","Model Trained!\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"Q-OJbZ72t6Yq"},"source":["## Evaluate CNN Model\n","\n","Now that we have trained a model for text classification, it is time to evaluate it. \n"]},{"cell_type":"code","metadata":{"id":"vTiiYDZIF--7"},"source":["def evaluate(model, data_loader, criterion):\n","    print('Evaluating performance on the test dataset...')\n","    model.eval()\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    all_predictions = []\n","    print(\"\\nSOME PREDICTIONS FROM THE MODEL:\")\n","    for texts, labels in tqdm(data_loader):\n","        texts = texts.to(device)\n","        labels = labels.to(device)\n","        \n","        output = model(texts)\n","        acc = accuracy(output, labels)\n","        pred = output.argmax(dim=1)\n","        all_predictions.append(pred)\n","        \n","        loss = criterion(output, labels)\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","        if random.random() < 0.0015:\n","            print(\"Input: \"+' '.join([data_loader.dataset.idx2word[idx] for idx in texts[0].tolist() if idx not in {data_loader.dataset.word2idx[PAD], data_loader.dataset.word2idx[END]}]))\n","            print(\"Prediction:\", pred.item(), '\\tCorrect Output:', labels.item(), '\\n')\n","\n","    full_acc = 100*epoch_acc/len(data_loader)\n","    full_loss = epoch_loss/len(data_loader)\n","    print('[TEST]\\t Loss: {:.4f}\\t Accuracy: {:.2f}%'.format(full_loss, full_acc))\n","    predictions = torch.cat(all_predictions)\n","    return predictions, full_acc, full_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z718w8e0oNoS","colab":{"base_uri":"https://localhost:8080/","height":687,"referenced_widgets":["2e3199e29b304ff399af87547d281df9","06caf14e6cfc42e693e4a15942145cf4","bf037dfbb8d5457880633eb14342c33c","26873b242a2c4e8aaaaaa2c721669154","2ea40a87b6754f51b098b496f89937b6","03d728f55d9b4ba09fa68d1a89fb1520","254cd25749054363b7da63b83b5a4400","96945065d56a47e58cee7386a45c2140","9c17974344134eff86c30b43c22654bd","dca9113a57a34d188cbc842c991d656c","898b3ecffa6d4c5aadeef09e762539e7"]},"executionInfo":{"status":"ok","timestamp":1646660310935,"user_tz":360,"elapsed":22090,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"c7aa52c4-f53b-4cd1-e144-09e6119de04e"},"source":["if __name__=='__main__':\n","    evaluate(cnn_model, test_loader, criterion) # Compute test data accuracy"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating performance on the test dataset...\n","\n","SOME PREDICTIONS FROM THE MODEL:\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e3199e29b304ff399af87547d281df9","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/5000 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Input: i couldn't help but think of behind the mask : the rise of leslie vernon ( a massively more amazing film ) when watching this because of the realistic feel to it as well as the great innovative idea . this could have been a <UNK> film . the acting <UNK> some of the actors alright . from <UNK> downright horrible.<br /><br />that aside the idea is great and the format is great . the story is pretty good as well , though suffering often from big blows to the logical mind.<br /><br <UNK> that though right ? it\n","Prediction: 1 \tCorrect Output: 0 \n","\n","Input: <UNK> <UNK> <UNK> is a vast improvement on <UNK> <UNK> <UNK> as it has sound mostly in the right places and a rudimentary plot . <UNK> time they've <UNK> slightly further away from the car park the other two movies were filmed in which is a good move as you can no longer hear cars driving past what is supposed to be a remote <UNK> /><br <UNK> time around there's a reality <UNK> show and a fake clown to scare off the contestants . <UNK> is hardly a new idea , <UNK> seen at least three other horror movies\n","Prediction: 0 \tCorrect Output: 0 \n","\n","Input: <UNK> truly frightening film . <UNK> as if it were made in the early ' 90s by a straight person who wanted to show that gays are good , normal , <UNK> people . <UNK> to the point of being offensive , <UNK> suggests that <UNK> and marriage are the preferred path to salvation for sad , lonely , sex-crazed gays . <UNK> ! <UNK> knew ? <UNK> supporting characters are caricatures of gay stereotypes ( the effeminate buffoon , the bitter , lonely queen , the <UNK> hag , etc. ) and the main characters are milquetoast ,\n","Prediction: 0 \tCorrect Output: 0 \n","\n","Input: <UNK> movie was a major disappointment on direction , intellectual <UNK> , plot and in the way it dealt with its subject , painting . <UNK> is a slow moving film set like an episode of <UNK> <UNK> , with appalling lack of depth though . <UNK> also fails to deliver its message in a convincing manner.<br /><br <UNK> approach to the subject of painting is very elite , limited to vague and subjective terms as \" <UNK> . <UNK> to the makers of this movie , ' beauty ' can be only experienced in <UNK> kitschy landscape paintings\n","Prediction: 0 \tCorrect Output: 0 \n","\n","Input: i'm not even sure what to say about this film . it's one of only a handful of movies ever made that i would consider romantic . to try to talk plot or performance or technical details about this film would be in the words of frank zappa \" like dancing about <UNK> . it absolutely hits the nail right on the head in the way it captures those fleeting moments in life that move us and then run away from us never to be experienced again . this seems like the movie the character version of charlie kaufman\n","Prediction: 1 \tCorrect Output: 1 \n","\n","Input: <UNK> when i was little i got this movie as a present and my sister and i loved it . we would watch it all the time . when our friends came over we would have <UNK> and we'd watch big rock candy mountain and <UNK> magical toys . <UNK> 21 now and i still love this movie , some old friends and i recently got together and watched it , we knew all the songs and we danced and talked about how much we hated <UNK> when we were little . <UNK> friend actually bought this movie and\n","Prediction: 1 \tCorrect Output: 1 \n","\n","Input: <UNK> the end of the movie i still don't know whether i liked it or not . <UNK> was the case with most of the reviewers . <UNK> none the less i still feel that the movie is worth a 7 for the amount of efforts put in . <br /><br />long ago i read a quote : <UNK> <UNK> 2 <UNK> <UNK> <UNK> , 1 . <UNK> <UNK> <UNK> <UNK> <UNK> . <UNK> 2 . <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . while here i feel that <UNK> <UNK> took this way too literally and left all\n","Prediction: 1 \tCorrect Output: 1 \n","\n","Input: <UNK> <UNK> , a movie that id had wanted to see for <UNK> <UNK> plays <UNK> <UNK> ( jack the ripper ) a <UNK> pose to <UNK> , and his literally killer plan to knock off a highly <UNK> man and his family.<br /><br <UNK> everyday woman \" <UNK> \" ( <UNK> think ) is a normal woman , goes to work , <UNK> to <UNK> /><br <UNK> death of her grandmother sends her on a flight which delayed several times.<br /><br />a flight where she meets <UNK> ordinary seeming guy , until he <UNK> reveals his profession and\n","Prediction: 1 \tCorrect Output: 1 \n","\n","Input: <UNK> was a hilarious movie and <UNK> would see it again and again . <UNK> isn't a movie for someone who doesn't have a fun sense of a humor , but for people who <UNK> comedy like <UNK> <UNK> its a perfect movie in my opinion . <UNK> is really <UNK>\n","Prediction: 1 \tCorrect Output: 1 \n","\n","Input: <UNK> in a while , a film comes along that raises the bar for every other film in its genre . <UNK> film of this caliber will influence many films following its release for years to come . <UNK> <UNK> <UNK> <UNK> ' falls in this category . <UNK> is arguably one of the best horror films made during the 1980's ; possibly one of the best ever made.<br /><br <UNK> filmmakers have crafted a movie that appeals to every horror fan . <UNK> story is engrossing and original . <UNK> villains are appropriately menacing and frightening . <UNK>\n","Prediction: 1 \tCorrect Output: 1 \n","\n","[TEST]\t Loss: 0.8978\t Accuracy: 77.02%\n"]}]},{"cell_type":"markdown","metadata":{"id":"BRCFvjwDthiA"},"source":["# Step 4: Train a Recurrent Neural Network (RNN)\n","Build a text clasification model that is based on **recurrent neural network**."]},{"cell_type":"markdown","metadata":{"id":"Y-t8tlZviV2x"},"source":["## Define the RNN Model\n","\n","Define the methods for RNN, `__init__(...)` and `forward(...)` are the most important ones."]},{"cell_type":"code","metadata":{"id":"2nc_HxbP6klI"},"source":["class RNN(nn.Module):\n","    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, bidirectional, dropout, num_classes, pad_idx):\n","        super(RNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","\n","        if bidirectional:\n","            self.num_dirs = 2\n","        else:\n","            self.num_dirs = 1\n","\n","        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n","        #   to represent the words in the vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n","        self.EmbeddingLayer = nn.Embedding(vocab_size, embed_size)        \n","\n","        # Create a recurrent network (use nn.GRU) with batch_first = True\n","        # Make sure to use hidden_size, num_layers, dropout, and bidirectional here.\n","        # Note: If parameter \"dropout\" is non-zero, it introduces a Dropout layer on the outputs \n","        # of each GRU layer except the last layer, with dropout probability equal to dropout, Default: 0\n","        self.rnn = nn.GRU(embed_size, hidden_size, num_layers, batch_first = True, dropout = dropout, bidirectional = bidirectional)\n","        \n","        \n","        # Create a dropout layer (nn.Dropout) using dropout\n","        # Note: this dropout is for the last layer of GRU, i.e. for the input of the linear layer after GRU\n","        self.DropoutLayer = nn.Dropout(dropout)\n","\n","        # Define a linear layer (nn.Linear) that consists of num_classes units \n","        #   and takes as input the output of the last timestep. In the bidirectional case, need to concatenate\n","        #   the output of the last timestep of the forward direction with the output of the last timestep of the backward direction.\n","        # Note: see Pytorch documentation for GRU, its output has a size of D * H_out, where D is 2 if\n","        # bidirectional = True, and 1 otherwise; H_out = hidden_size, therefore we have the following self.num_dirs * hiddne_size\n","        self.LinearLayer = nn.Linear(self.num_dirs * hidden_size, num_classes)\n","\n","\n","    def forward(self, texts):\n","        \"\"\"\n","        texts: LongTensor [batch_size, MAX_LEN]\n","        \n","        Returns output: Tensor [batch_size, num_classes]\n","        \"\"\"\n","\n","        # Pass texts through the embedding layer to convert from word ids to word embeddings\n","        #   Resulting: shape: [batch_size, max_len, embed_size]\n","        embeddings  = self.EmbeddingLayer(texts)\n","\n","        # Pass the result through the recurrent network\n","        #   See PyTorch documentation for resulting shape for nn.GRU\n","        _, h_n = self.rnn(embeddings)\n","        \n","        # Concatenate the outputs of the last timestep for each direction \n","        #   This depends on whether or not the model is bidirectional.\n","        #   Resulting shape: [batch_size, num_dirs*hidden_size]\n","\n","        # according to GRU ducumentation, h_n is tensor of shape [num_layers*num_dirs, batch_size, hidden_size]\n","        # it can be viewed as if it is the shape of [num_layers, num_dirs, batch_size, hidden_size]. \n","        # On the first dimension with range num_layers, if bidirectional, \n","        # layer 1 (index 0) has its forward and backword output as h_n[0], h_n[1]\n","        # layer 2 (index 1) has its forward and backward output as h_n[2], h_n[3], ...\n","        # the last layer has the last two elements as its forward and backward output, so h_n[-2] and h_n[-1] \n","        # If not bidirectional, only forward direction, we have the first layer's output as h_n[0]..., last layer's h_n[-1]\n","        # in the following, we only need the last layer's output\n","        if self.num_dirs == 2:\n","            RnnOutput = torch.cat([h_n[-2],h_n[-1]],dim = 1)\n","        else:\n","            RnnOutput = h_n[-1]\n","        # Apply dropout\n","        DropoutRnnOutput = self.DropoutLayer(RnnOutput)\n","\n","        # Pass the output through the linear layer and return its output \n","        #   Resulting shape: [batch_size, num_classes]\n","        output = self.LinearLayer(DropoutRnnOutput)\n","\n","        #NOTE: Do not apply a sigmoid or softmax to the final output - done in training method!\n","        \n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"baD8lYAytdTV"},"source":["## Train RNN Model\n","First, we initialize the train and test dataloaders."]},{"cell_type":"code","metadata":{"id":"WCzNm8LDM5aT"},"source":["if __name__=='__main__':\n","    THRESHOLD = 5 # Don't change this\n","    MAX_LEN = 100 # Don't change this\n","    BATCH_SIZE = 32 # Feel free to try other batch sizes\n","\n","    train_Ds = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n","    train_loader = torch.utils.data.DataLoader(train_Ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n","\n","    test_Ds = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_Ds.idx2word, train_Ds.word2idx)\n","    test_loader = torch.utils.data.DataLoader(test_Ds, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lp5pAz8emxi2"},"source":["Now instantiate the model with some hyperparameters values"]},{"cell_type":"code","metadata":{"id":"CA-UairGErap","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646664567966,"user_tz":360,"elapsed":187,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"789cebef-e1e3-4863-984a-74abcda2cca7"},"source":["if __name__=='__main__':\n","    rnn_model = RNN(vocab_size = train_Ds.vocab_size, # Don't change this\n","                embed_size = 128, \n","                hidden_size = 128, \n","                num_layers = 2,\n","                bidirectional = True,\n","                dropout = 0.5,\n","                num_classes = 2, # Don't change this\n","                pad_idx = train_Ds.word2idx[PAD]) # Don't change this\n","\n","    # Put the model on device\n","    rnn_model = rnn_model.to(device)\n","\n","    print('The model has {:,d} trainable parameters'.format(count_parameters(rnn_model)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 4,300,546 trainable parameters\n"]}]},{"cell_type":"markdown","metadata":{"id":"LqngFY4MoLec"},"source":["Here, we create the criterion and optimizer; as with the CNN, we use cross-entropy loss and Adam optimization."]},{"cell_type":"code","metadata":{"id":"em6Rs58OlJ3Z"},"source":["if __name__=='__main__':    \n","    LEARNING_RATE = 5e-4 # Feel free to try other learning rates\n","\n","    # Define the loss function\n","    criterion = nn.CrossEntropyLoss().to(device)\n","\n","    # Define the optimizer\n","    optimizer = optim.Adam(rnn_model.parameters(), lr=LEARNING_RATE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uEPsi3choUm5"},"source":["Finally, we can train the model. We use the same `train_model(...)` function that we defined for the CNN."]},{"cell_type":"code","metadata":{"id":"NR8Wckf0l2G7","colab":{"base_uri":"https://localhost:8080/","height":376,"referenced_widgets":["b665db8e5f434150b58ed52a2cbbb2e3","18fe064f7b464f1e89f7e33e24612700","b8dd72fb4d8741369ce0f7f401f2a344","178ab661efe0432a8dbec20cd57fef31","50093ecf692b42d09a218126ae0ec70b","73d4c23c95a54557b08be17c605275d2","6c21b60f7f8f46d6861dc8b1da02f06f","52e9f9243a904588a8cd62f0c23a7491","bb847fc0eee844d4879b0cd34df34b7d","4a5025178f4d409c8a8ab63b3a65538b","76c82ad6961e4acba5555c7970f03471"]},"executionInfo":{"status":"ok","timestamp":1646665244752,"user_tz":360,"elapsed":671483,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"92837486-bcfb-4dcc-e735-5051db9a770c"},"source":["if __name__=='__main__':    \n","    N_EPOCHS = 15 # Feel free to change this\n","    \n","    # train model for N_EPOCHS epochs\n","    train_model(rnn_model, N_EPOCHS, train_loader, optimizer, criterion)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Model...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b665db8e5f434150b58ed52a2cbbb2e3","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/15 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[TRAIN]\t Epoch:  1\t Loss: 0.6584\t Train Accuracy: 59.77%\n","[TRAIN]\t Epoch:  2\t Loss: 0.5054\t Train Accuracy: 75.36%\n","[TRAIN]\t Epoch:  3\t Loss: 0.3927\t Train Accuracy: 82.33%\n","[TRAIN]\t Epoch:  4\t Loss: 0.3041\t Train Accuracy: 87.32%\n","[TRAIN]\t Epoch:  5\t Loss: 0.2299\t Train Accuracy: 91.11%\n","[TRAIN]\t Epoch:  6\t Loss: 0.1595\t Train Accuracy: 94.12%\n","[TRAIN]\t Epoch:  7\t Loss: 0.1046\t Train Accuracy: 96.28%\n","[TRAIN]\t Epoch:  8\t Loss: 0.0652\t Train Accuracy: 97.96%\n","[TRAIN]\t Epoch:  9\t Loss: 0.0411\t Train Accuracy: 98.66%\n","[TRAIN]\t Epoch: 10\t Loss: 0.0319\t Train Accuracy: 98.95%\n","[TRAIN]\t Epoch: 11\t Loss: 0.0257\t Train Accuracy: 99.11%\n","[TRAIN]\t Epoch: 12\t Loss: 0.0189\t Train Accuracy: 99.35%\n","[TRAIN]\t Epoch: 13\t Loss: 0.0204\t Train Accuracy: 99.31%\n","[TRAIN]\t Epoch: 14\t Loss: 0.0140\t Train Accuracy: 99.53%\n","[TRAIN]\t Epoch: 15\t Loss: 0.0117\t Train Accuracy: 99.59%\n","Model Trained!\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"j-SRIFfooYk6"},"source":["## Evaluate RNN Model\n"]},{"cell_type":"code","metadata":{"id":"HYon4AbHl5_M","colab":{"base_uri":"https://localhost:8080/","height":437,"referenced_widgets":["dca0f30827954ca2877ba3477446b3dc","bbae0859c58c428691d1c82708951d83","46bfa3fe11094c52936a1ae816c26934","95553186959e4070b7840a6af5e9f9d9","492f798164fb493fb5323ba37edf4fd5"]},"executionInfo":{"status":"ok","timestamp":1633644664978,"user_tz":300,"elapsed":89166,"user":{"displayName":"Henry Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06659551641654316375"}},"outputId":"a41d0bac-b02c-40c2-8824-77a78e58a46d"},"source":["if __name__=='__main__':    \n","    evaluate(rnn_model, test_loader, criterion) # Compute test data accuracy"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating performance on the test dataset...\n","\n","SOME PREDICTIONS FROM THE MODEL:\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dca0f30827954ca2877ba3477446b3dc","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/5000 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Input: <UNK> , <UNK> wrote this review in anger at <UNK> <UNK> and <UNK> /><br <UNK> has produced movies based on one of the darkest days of our nation . 911 changed everything . <UNK> changed our perception of security . <UNK> changed our understanding of the evil of man and humanity . <UNK> importantly and devastatingly  , it changed our world.<br /><br <UNK> , <UNK> can't not stress how utterly repulsed , disillusioned , and angry <UNK> am at the careless , blatant ignorance of <UNK> seeking to make a lucrative profit out of death and destruction .\n","Prediction: 0 \tCorrect Output: 0 \n","\n","Input: <UNK> review good movies when you can review \" <UNK> <UNK> /><br <UNK> , this film is soooo lame . <UNK> can just picture the cast and crew driving around <UNK> . with a camcorder , hurling extras in silly monster make-up at poor , long-suffering <UNK> <UNK> . <UNK> stars ' families actually turn up to play cameos , probably because <UNK> <UNK> couldn't afford \" real \" extras . <UNK> effects , lame sets , and a script so convoluted it would take <UNK> to <UNK> all the knots - this must be classic <UNK> /><br <UNK>\n","Prediction: 0 \tCorrect Output: 0 \n","\n","Input: <UNK> always thought this would be a long and boring <UNK> flick full of static interior takes , dude , <UNK> was wrong . \" <UNK> \" is a highly fascinating and thoroughly captivating <UNK> , taking a deep and realistic view behind the origins of <UNK> . <UNK> are constantly on the move , and although as a viewer you kinda always remain an outsider , it's still possible to feel the suspense coming from certain decisions and ambitions of the characters . <UNK> <UNK> <UNK> succeeds in creating some truly opulent images due to meticulously composed lighting\n","Prediction: 1 \tCorrect Output: 1 \n","\n","Input: <UNK> <UNK> isn't playing with taboos or forcing an agenda like , say <UNK> or <UNK> ( though <UNK> like them <UNK> . <UNK> states the obvious in subtle , near subliminal remarks . <UNK> show won't change the <UNK> , nor is it meant to . <UNK> , along with the hilarious <UNK> <UNK> and <UNK> <UNK> ex-boyfriend <UNK> <UNK> of \" <UNK> . <UNK> \" fame , this is one mean show with an appetite for destruction ! <UNK> <UNK> were thoroughly wrecked by the first episode . <UNK> , <UNK> love this woman and like her\n","Prediction: 0 \tCorrect Output: 1 \n","\n","Input: <UNK> is one of the creepiest , scariest and most heartbreaking horror movie <UNK> ! <br /><br <UNK> <UNK> ( <UNK> ) and his family moving in to new home with his wife ( <UNK> , <UNK> ( <UNK> ) and little son ( <UNK> ) <UNK> seems normal until <UNK> <UNK> loses one his patient who had a terrible head <UNK> he is haunted by the ghost know as <UNK> takes him to the <UNK> <UNK> and show him that where the dead come to life.<br /><br <UNK> not knowing if that was all dream and is talking\n","Prediction: 1 \tCorrect Output: 1 \n","\n","Input: <UNK> could be well have been <UNK> definitive film noir of all time , had not the <UNK> <UNK> cut so much of <UNK> <UNK> original . <UNK> we are left with is a flawed , yet brilliant film that showcases the overwhelming talent of <UNK> as an <UNK> and <UNK> <UNK> as a serious dramatic talent.<br /><br <UNK> <UNK> <UNK> <UNK> ' is film noir at it's most sizzling and confusing . <UNK> , with an uneven accent , portrays <UNK> <UNK> , a <UNK> <UNK> , who , after a fateful encounter with the seductive , dangerous\n","Prediction: 1 \tCorrect Output: 1 \n","\n","[TEST]\t Loss: 1.5825\t Accuracy: 76.24%\n"]}]}]}